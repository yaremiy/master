"""
–ì–æ–ª–æ–≤–Ω–∏–π –∫–ª–∞—Å –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ –≤–µ–±—Å–∞–π—Ç—ñ–≤
"""

from playwright.async_api import async_playwright
from typing import Dict, Any, List
import asyncio
import re

from .metrics.perceptibility import PerceptibilityMetrics
from .metrics.operability import OperabilityMetrics  
from .metrics.understandability import UnderstandabilityMetrics
from .metrics.localization import LocalizationMetrics
from .utils.web_scraper import WebScraper
from .utils.calculator import ScoreCalculator


class AccessibilityEvaluator:
    """–ì–æ–ª–æ–≤–Ω–∏–π –∫–ª–∞—Å –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ –≤–µ–±—Å–∞–π—Ç—ñ–≤"""
    
    def __init__(self):
        self.weights = {
            'perceptibility': 0.3,
            'operability': 0.3, 
            'understandability': 0.4,
            'localization': 0.4
        }
        
        self.metric_weights = {
            'alt_text': 0.15,
            'contrast': 0.15,
            'media_accessibility': 0.15,
            'keyboard_navigation': 0.05,
            'structured_navigation': 0.05,
            'instruction_clarity': 0.1,
            'input_assistance': 0.1,
            'error_support': 0.1,
            'localization': 0.15
        }
        
        # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä—ñ–≤ –º–µ—Ç—Ä–∏–∫
        self.perceptibility = PerceptibilityMetrics()
        self.operability = OperabilityMetrics()
        self.understandability = UnderstandabilityMetrics()
        self.localization = LocalizationMetrics()
        
        self.web_scraper = WebScraper()
        self.calculator = ScoreCalculator(self.weights, self.metric_weights)
    
    async def evaluate_accessibility(self, url: str) -> Dict[str, Any]:
        """
        –ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ –≤–µ–±—Å–∞–π—Ç—É
        
        Args:
            url: URL –≤–µ–±—Å–∞–π—Ç—É –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
            
        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª—ñ–∑—É
        """
        try:
            # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑ –≤–µ–±—Å–∞–π—Ç—É
            page_data = await self.web_scraper.scrape_page(url)
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –≤—Å—ñ—Ö –º–µ—Ç—Ä–∏–∫
            metrics = await self.calculate_all_metrics(page_data)
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –ø—ñ–¥—Å–∫–æ—Ä—ñ–≤
            subscores = self.calculator.calculate_subscores(metrics)
            
            # –§—ñ–Ω–∞–ª—å–Ω–∏–π —Å–∫–æ—Ä
            final_score = self.calculator.calculate_final_score(subscores)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
            recommendations = self.generate_recommendations(metrics)
            
            return {
                'url': url,
                'metrics': metrics,
                'subscores': subscores,
                'final_score': final_score,
                'recommendations': recommendations,
                'axe_results': page_data.get('axe_results', {}),  # –î–æ–¥–∞—î–º–æ axe_results
                'detailed_analysis': await self._generate_detailed_analysis(page_data),  # –î–æ–¥–∞—î–º–æ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'url': url,
                'error': str(e),
                'status': 'error'
            }
    
    async def calculate_all_metrics(self, page_data: Dict[str, Any]) -> Dict[str, float]:
        """–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –≤—Å—ñ—Ö –º–µ—Ç—Ä–∏–∫ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ"""
        
        metrics = {}
        
        # –ü–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å
        metrics.update(await self.perceptibility.calculate_metrics(page_data))
        
        # –ö–µ—Ä–æ–≤–∞–Ω—ñ—Å—Ç—å
        metrics.update(await self.operability.calculate_metrics(page_data))
        
        # –ó—Ä–æ–∑—É–º—ñ–ª—ñ—Å—Ç—å
        metrics.update(await self.understandability.calculate_metrics(page_data))
        
        # –õ–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—è
        metrics.update(await self.localization.calculate_metrics(page_data))
        
        return metrics
    
    def generate_recommendations(self, metrics: Dict[str, float]) -> List[Dict[str, str]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –º–µ—Ç—Ä–∏–∫"""
        
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É
        if metrics.get('alt_text', 0) < 0.8:
            recommendations.append({
                'category': '–ü–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å',
                'issue': '–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É',
                'recommendation': '–î–æ–¥–∞–π—Ç–µ –∑–º—ñ—Å—Ç–æ–≤–Ω—ñ alt –∞—Ç—Ä–∏–±—É—Ç–∏ –¥–æ –≤—Å—ñ—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å',
                'priority': '–í–∏—Å–æ–∫–∏–π',
                'wcag_reference': 'WCAG 1.1.1'
            })
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç—É
        if metrics.get('contrast', 0) < 0.7:
            recommendations.append({
                'category': '–ü–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω—ñ—Å—Ç—å',
                'issue': '–ù–∏–∑—å–∫–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç —Ç–µ–∫—Å—Ç—É',
                'recommendation': '–ü—ñ–¥–≤–∏—â—Ç–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç –¥–æ –º—ñ–Ω—ñ–º—É–º 4.5:1 –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É',
                'priority': '–í–∏—Å–æ–∫–∏–π',
                'wcag_reference': 'WCAG 1.4.3'
            })
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –∫–ª–∞–≤—ñ–∞—Ç—É—Ä–Ω–æ—ó –Ω–∞–≤—ñ–≥–∞—Ü—ñ—ó
        if metrics.get('keyboard_navigation', 0) < 0.9:
            recommendations.append({
                'category': '–ö–µ—Ä–æ–≤–∞–Ω—ñ—Å—Ç—å',
                'issue': '–ü—Ä–æ–±–ª–µ–º–∏ –∑ –∫–ª–∞–≤—ñ–∞—Ç—É—Ä–Ω–æ—é –Ω–∞–≤—ñ–≥–∞—Ü—ñ—î—é',
                'recommendation': '–ó–∞–±–µ–∑–ø–µ—á—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—ñ—Å—Ç—å –≤—Å—ñ—Ö —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ —á–µ—Ä–µ–∑ –∫–ª–∞–≤—ñ–∞—Ç—É—Ä—É',
                'priority': '–í–∏—Å–æ–∫–∏–π',
                'wcag_reference': 'WCAG 2.1.1'
            })
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –∑—Ä–æ–∑—É–º—ñ–ª–æ—Å—Ç—ñ
        if metrics.get('instruction_clarity', 0) < 0.7:
            recommendations.append({
                'category': '–ó—Ä–æ–∑—É–º—ñ–ª—ñ—Å—Ç—å',
                'issue': '–°–∫–ª–∞–¥–Ω—ñ –∞–±–æ –Ω–µ–∑—Ä–æ–∑—É–º—ñ–ª—ñ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó',
                'recommendation': '–°–ø—Ä–æ—Å—Ç—ñ—Ç—å –º–æ–≤—É —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π —Ç–∞ –∑—Ä–æ–±—ñ—Ç—å —ó—Ö –±—ñ–ª—å—à –∑—Ä–æ–∑—É–º—ñ–ª–∏–º–∏',
                'priority': '–°–µ—Ä–µ–¥–Ω—ñ–π',
                'wcag_reference': 'WCAG 3.1.5'
            })
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –¥–ª—è –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó
        if metrics.get('localization', 0) < 0.6:
            recommendations.append({
                'category': '–õ–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—è',
                'issue': '–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ –º–æ–≤',
                'recommendation': '–î–æ–¥–∞–π—Ç–µ –ø—ñ–¥—Ç—Ä–∏–º–∫—É —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó —Ç–∞ –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—ó –º–æ–≤',
                'priority': '–°–µ—Ä–µ–¥–Ω—ñ–π',
                'wcag_reference': 'WCAG 3.1.2'
            })
        
        return recommendations
    
    async def evaluate_html_content(self, html_content: str, base_url: str = "http://localhost", title: str = "HTML Document") -> Dict[str, Any]:
        """
        –û—Ü—ñ–Ω–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ HTML –∫–æ–Ω—Ç–µ–Ω—Ç—É –±–µ–∑ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∑ URL
        
        Args:
            html_content: HTML –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
            base_url: –ë–∞–∑–æ–≤–∏–π URL –¥–ª—è –≤—ñ–¥–Ω–æ—Å–Ω–∏—Ö –ø–æ—Å–∏–ª–∞–Ω—å
            title: –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            
        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª—ñ–∑—É
        """
        try:
            # –°—Ç–≤–æ—Ä—é—î–º–æ page_data –∑ HTML –∫–æ–Ω—Ç–µ–Ω—Ç—É
            page_data = await self._create_page_data_from_html(html_content, base_url, title)
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –≤—Å—ñ—Ö –º–µ—Ç—Ä–∏–∫
            metrics = await self.calculate_all_metrics(page_data)
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –ø—ñ–¥—Å–∫–æ—Ä—ñ–≤
            subscores = self.calculator.calculate_subscores(metrics)
            
            # –§—ñ–Ω–∞–ª—å–Ω–∏–π —Å–∫–æ—Ä
            final_score = self.calculator.calculate_final_score(subscores)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π
            recommendations = self.generate_recommendations(metrics)
            
            return {
                'url': f"{base_url} (HTML –∫–æ–Ω—Ç–µ–Ω—Ç)",
                'metrics': metrics,
                'subscores': subscores,
                'final_score': final_score,
                'recommendations': recommendations,
                'detailed_analysis': await self._generate_detailed_analysis(page_data),
                'status': 'success'
            }
            
        except Exception as e:
            return {
                'url': f"{base_url} (HTML –∫–æ–Ω—Ç–µ–Ω—Ç)",
                'error': str(e),
                'status': 'error'
            }
    
    async def _create_page_data_from_html(self, html_content: str, base_url: str, title: str) -> Dict[str, Any]:
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è page_data –∑ HTML –∫–æ–Ω—Ç–µ–Ω—Ç—É –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É"""
        
        from playwright.async_api import async_playwright
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                print(f"üìÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è HTML –∫–æ–Ω—Ç–µ–Ω—Ç—É...")
                
                # –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ HTML –∫–æ–Ω—Ç–µ–Ω—Ç
                await page.set_content(html_content, wait_until="domcontentloaded")
                
                # –ó–±–∏—Ä–∞—î–º–æ –¥–∞–Ω—ñ –∞–Ω–∞–ª–æ–≥—ñ—á–Ω–æ –¥–æ web_scraper
                print("üîç –ó–±—ñ—Ä —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤...")
                interactive_elements = await self.web_scraper._get_interactive_elements(page)
                
                print("üìù –ó–±—ñ—Ä —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤...")
                text_elements = await self.web_scraper._get_text_elements(page)
                
                print("üé¨ –ó–±—ñ—Ä –º–µ–¥—ñ–∞ –µ–ª–µ–º–µ–Ω—Ç—ñ–≤...")
                media_elements = await self.web_scraper._get_media_elements(page)
                
                print("üìã –ó–±—ñ—Ä —Ñ–æ—Ä–º...")
                form_elements = await self.web_scraper._get_form_elements(page)
                
                print("üé® –ó–±—ñ—Ä —Å—Ç–∏–ª—ñ–≤...")
                computed_styles = await self.web_scraper._get_computed_styles(page)
                
                print("üîç –ó–∞–ø—É—Å–∫ axe-core –∞–Ω–∞–ª—ñ–∑—É...")
                axe_results = await self.web_scraper._run_axe_core(page)
                
                print("‚å®Ô∏è –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–ª–∞–≤—ñ–∞—Ç—É—Ä–Ω–æ—ó –Ω–∞–≤—ñ–≥–∞—Ü—ñ—ó...")
                focus_test_results = await self.web_scraper._test_keyboard_focus(page)
                
                print("üß™ –î–∏–Ω–∞–º—ñ—á–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ñ–æ—Ä–º...")
                form_error_test_results = await self.web_scraper._test_form_error_behavior(page)
                
                page_data = {
                    'url': base_url,
                    'html_content': html_content,
                    'title': title,
                    'page_depth': 0,  # HTML –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –º–∞—î –≥–ª–∏–±–∏–Ω–∏
                    'interactive_elements': interactive_elements,
                    'text_elements': text_elements,
                    'media_elements': media_elements,
                    'form_elements': form_elements,
                    'computed_styles': computed_styles,
                    'axe_results': axe_results,
                    'focus_test_results': focus_test_results,  # –î–æ–¥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ñ–æ–∫—É—Å—É
                    'form_error_test_results': form_error_test_results  # –î–æ–¥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–∏–Ω–∞–º—ñ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ñ–æ—Ä–º
                }
                
                print(f"‚úÖ –ó–±—ñ—Ä –¥–∞–Ω–∏—Ö –∑ HTML –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ó–Ω–∞–π–¥–µ–Ω–æ:")
                print(f"   üìù –¢–µ–∫—Å—Ç–æ–≤–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤: {len(text_elements)}")
                print(f"   üîó –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤: {len(interactive_elements)}")
                print(f"   üé¨ –ú–µ–¥—ñ–∞ –µ–ª–µ–º–µ–Ω—Ç—ñ–≤: {len(media_elements)}")
                print(f"   üìã –§–æ—Ä–º: {len(form_elements)}")
                
                return page_data
                
            finally:
                await browser.close()
    
    async def _generate_detailed_analysis(self, page_data: Dict[str, Any]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É –¥–ª—è UI"""
        
        axe_results = page_data.get('axe_results', {})
        
        detailed_analysis = {
            'alt_text': self._analyze_alt_text_details(axe_results),
            'contrast': self._analyze_contrast_details(axe_results),
            'structured_navigation': self._analyze_headings_details(axe_results),
            'keyboard_navigation': self._analyze_keyboard_details(page_data),  # –ü–µ—Ä–µ–¥–∞—î–º–æ page_data –∑–∞–º—ñ—Å—Ç—å axe_results
            'instruction_clarity': self._analyze_instructions_details(page_data),
            'input_assistance': self._analyze_input_assistance_details(page_data),
            'error_support': self._analyze_error_support_details(page_data),
            'media_accessibility': self._analyze_media_details(page_data),  # –ü–µ—Ä–µ–¥–∞—î–º–æ page_data –∑–∞–º—ñ—Å—Ç—å axe_results
            'localization': self._analyze_localization_details(page_data)
        }
        
        return detailed_analysis
    
    def _analyze_alt_text_details(self, axe_results: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ alt-text"""
        
        details = {
            'total_images': 0,
            'correct_images': 0,
            'problematic_images': [],
            'correct_images_list': [],
            'score_explanation': ''
        }
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ image-alt –ø—Ä–∞–≤–∏–ª–æ
        violations = self._get_axe_rule_results(axe_results, 'violations', 'image-alt')
        passes = self._get_axe_rule_results(axe_results, 'passes', 'image-alt')
        
        # –ü—Ä–æ–±–ª–µ–º–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        if violations:
            for node in violations.get('nodes', []):
                details['problematic_images'].append({
                    'selector': node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])[0] if node.get('target') else '–Ω–µ–≤—ñ–¥–æ–º–æ',
                    'html': node.get('html', ''),
                    'issue': node.get('failureSummary', '–í—ñ–¥—Å—É—Ç–Ω—ñ–π alt –∞—Ç—Ä–∏–±—É—Ç'),
                    'impact': violations.get('impact', 'unknown')
                })
        
        # –ü—Ä–∞–≤–∏–ª—å–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        if passes:
            for node in passes.get('nodes', []):
                # –í–∏—Ç—è–≥—É—î–º–æ alt —Ç–µ–∫—Å—Ç –∑ HTML
                html = node.get('html', '')
                import re
                alt_match = re.search(r'alt="([^"]*)"', html) if 'alt=' in html else None
                alt_text = alt_match.group(1) if alt_match else '–ü–æ—Ä–æ–∂–Ω—ñ–π alt=""'
                
                details['correct_images_list'].append({
                    'selector': node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])[0] if node.get('target') else '–Ω–µ–≤—ñ–¥–æ–º–æ',
                    'html': html,
                    'alt_text': alt_text
                })
        
        details['total_images'] = len(details['problematic_images']) + len(details['correct_images_list'])
        details['correct_images'] = len(details['correct_images_list'])
        
        if details['total_images'] > 0:
            score = details['correct_images'] / details['total_images']
            details['score_explanation'] = f"–°–∫–æ—Ä: {details['correct_images']}/{details['total_images']} = {score:.3f}"
        else:
            details['score_explanation'] = "–ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
        
        return details
    
    def _analyze_contrast_details(self, axe_results: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∫–æ–Ω—Ç—Ä–∞—Å—Ç—É"""
        
        details = {
            'total_elements': 0,
            'correct_elements': 0,
            'problematic_elements': [],
            'correct_elements_list': [],
            'score_explanation': ''
        }
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ color-contrast –ø—Ä–∞–≤–∏–ª–æ
        violations = self._get_axe_rule_results(axe_results, 'violations', 'color-contrast')
        passes = self._get_axe_rule_results(axe_results, 'passes', 'color-contrast')
        
        # –ü—Ä–æ–±–ª–µ–º–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏
        if violations:
            for node in violations.get('nodes', []):
                # –í–∏—Ç—è–≥—É—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç –∑ failureSummary
                failure_summary = node.get('failureSummary', '')
                contrast_info = self._extract_contrast_info(failure_summary)
                
                details['problematic_elements'].append({
                    'selector': node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])[0] if node.get('target') else '–Ω–µ–≤—ñ–¥–æ–º–æ',
                    'html': node.get('html', ''),
                    'issue': failure_summary,
                    'contrast_ratio': contrast_info.get('actual', '–Ω–µ–≤—ñ–¥–æ–º–æ'),
                    'required_ratio': contrast_info.get('required', '–Ω–µ–≤—ñ–¥–æ–º–æ'),
                    'foreground': contrast_info.get('foreground', '–Ω–µ–≤—ñ–¥–æ–º–æ'),
                    'background': contrast_info.get('background', '–Ω–µ–≤—ñ–¥–æ–º–æ')
                })
        
        # –ü—Ä–∞–≤–∏–ª—å–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏
        if passes:
            for node in passes.get('nodes', []):
                details['correct_elements_list'].append({
                    'selector': node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])[0] if node.get('target') else '–Ω–µ–≤—ñ–¥–æ–º–æ',
                    'html': node.get('html', ''),
                    'status': '–ö–æ–Ω—Ç—Ä–∞—Å—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î WCAG —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º'
                })
        
        details['total_elements'] = len(details['problematic_elements']) + len(details['correct_elements_list'])
        details['correct_elements'] = len(details['correct_elements_list'])
        
        if details['total_elements'] > 0:
            score = details['correct_elements'] / details['total_elements']
            details['score_explanation'] = f"–°–∫–æ—Ä: {details['correct_elements']}/{details['total_elements']} = {score:.3f}"
        else:
            details['score_explanation'] = "–¢–µ–∫—Å—Ç–æ–≤—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
        
        return details
    
    def _extract_contrast_info(self, failure_summary: str) -> Dict[str, str]:
        """–í–∏—Ç—è–≥—É—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç –∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É"""
        
        import re
        
        info = {}
        
        # –®—É–∫–∞—î–º–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç ratio
        ratio_match = re.search(r'contrast of ([\d.]+)', failure_summary)
        if ratio_match:
            info['actual'] = ratio_match.group(1) + ':1'
        
        # –®—É–∫–∞—î–º–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç
        required_match = re.search(r'Expected contrast ratio of ([\d.]+):1', failure_summary)
        if required_match:
            info['required'] = required_match.group(1) + ':1'
        
        # –®—É–∫–∞—î–º–æ –∫–æ–ª—å–æ—Ä–∏
        fg_match = re.search(r'foreground color: (#[a-fA-F0-9]+)', failure_summary)
        if fg_match:
            info['foreground'] = fg_match.group(1)
        
        bg_match = re.search(r'background color: (#[a-fA-F0-9]+)', failure_summary)
        if bg_match:
            info['background'] = bg_match.group(1)
        
        return info
    
    def _analyze_headings_details(self, axe_results: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤"""
        
        details = {
            'total_headings': 0,
            'correct_headings': 0,
            'problematic_headings': [],
            'correct_headings_list': [],
            'score_explanation': ''
        }
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø—Ä–∞–≤–∏–ª–∞ –∑–∞–≥–æ–ª–æ–≤–∫—ñ–≤
        heading_rules = ['heading-order', 'page-has-heading-one', 'empty-heading']
        
        for rule_id in heading_rules:
            violations = self._get_axe_rule_results(axe_results, 'violations', rule_id)
            passes = self._get_axe_rule_results(axe_results, 'passes', rule_id)
            
            # –ü—Ä–æ–±–ª–µ–º–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            if violations:
                for node in violations.get('nodes', []):
                    details['problematic_headings'].append({
                        'selector': node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])[0] if node.get('target') else '–Ω–µ–≤—ñ–¥–æ–º–æ',
                        'html': node.get('html', ''),
                        'rule': rule_id,
                        'issue': node.get('failureSummary', violations.get('description', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø—Ä–æ–±–ª–µ–º–∞'))
                    })
            
            # –ü—Ä–∞–≤–∏–ª—å–Ω—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            if passes:
                for node in passes.get('nodes', []):
                    details['correct_headings_list'].append({
                        'selector': node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])[0] if node.get('target') else '–Ω–µ–≤—ñ–¥–æ–º–æ',
                        'html': node.get('html', ''),
                        'rule': rule_id,
                        'status': '–ü—Ä–∞–≤–∏–ª—å–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞'
                    })
        
        details['total_headings'] = len(details['problematic_headings']) + len(details['correct_headings_list'])
        details['correct_headings'] = len(details['correct_headings_list'])
        
        if details['total_headings'] > 0:
            score = details['correct_headings'] / details['total_headings']
            details['score_explanation'] = f"–°–∫–æ—Ä: {details['correct_headings']}/{details['total_headings']} = {score:.3f}"
        else:
            details['score_explanation'] = "–ó–∞–≥–æ–ª–æ–≤–∫–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
        
        return details
    
    def _analyze_keyboard_details(self, page_data: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∫–ª–∞–≤—ñ–∞—Ç—É—Ä–Ω–æ—ó –Ω–∞–≤—ñ–≥–∞—Ü—ñ—ó –∑ —Ä–µ–∞–ª—å–Ω–∏–º —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è–º —Ñ–æ–∫—É—Å—É"""
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ñ–æ–∫—É—Å—É
        focus_test_results = page_data.get('focus_test_results', [])
        
        details = {
            'total_elements': 0,
            'accessible_elements': 0,
            'problematic_elements': [],
            'accessible_elements_list': [],
            'score_explanation': ''
        }
        
        if not focus_test_results:
            details['score_explanation'] = "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –∫–ª–∞–≤—ñ–∞—Ç—É—Ä–Ω–æ—ó –Ω–∞–≤—ñ–≥–∞—Ü—ñ—ó –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ"
            return details
        
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω—ñ —Ç–∞ –ø—Ä–æ–±–ª–µ–º–Ω—ñ
        for result in focus_test_results:
            element_info = {
                'selector': result.get('selector', '–Ω–µ–≤—ñ–¥–æ–º–æ'),
                'html': result.get('html', ''),
                'tag': result.get('tag', 'unknown'),
                'rule': 'focus-test',  # –ü–æ–∑–Ω–∞—á–∞—î–º–æ —è–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
            }
            
            if result.get('focusable', False):
                element_info['status'] = result.get('focus_reason', '–î–æ—Å—Ç—É–ø–Ω–∏–π –∑ –∫–ª–∞–≤—ñ–∞—Ç—É—Ä–∏')
                details['accessible_elements_list'].append(element_info)
            else:
                element_info['issue'] = result.get('non_focus_reason', '–ù–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π –∑ –∫–ª–∞–≤—ñ–∞—Ç—É—Ä–∏')
                details['problematic_elements'].append(element_info)
        
        details['total_elements'] = len(focus_test_results)
        details['accessible_elements'] = len(details['accessible_elements_list'])
        
        if details['total_elements'] > 0:
            score = details['accessible_elements'] / details['total_elements']
            details['score_explanation'] = f"–°–∫–æ—Ä: {details['accessible_elements']}/{details['total_elements']} = {score:.3f} (—Ä–µ–∞–ª—å–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è —Ñ–æ–∫—É—Å—É)"
        else:
            details['score_explanation'] = "–Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
        
        return details
    
    def _analyze_instructions_details(self, page_data: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∑—Ä–æ–∑—É–º—ñ–ª–æ—Å—Ç—ñ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ–π"""
        
        html_content = page_data.get('html_content', '')
        
        # –í–∏—Ç—è–≥—É—î–º–æ —Ç—ñ–ª—å–∫–∏ labels –¥–ª—è input –ø–æ–ª—ñ–≤
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        instructions = []
        
        # –®—É–∫–∞—î–º–æ labels –ø–æ–≤'—è–∑–∞–Ω—ñ –∑ input –ø–æ–ª—è–º–∏
        labels = soup.find_all('label')
        for label in labels:
            text = label.get_text().strip()
            if text and len(text) >= 2:  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ –¥–ª—è label
                instructions.append({
                    'text': text,
                    'element': 'label',
                    'for': label.get('for', '–Ω–µ–≤—ñ–¥–æ–º–æ')
                })
        
        # –¢–∞–∫–æ–∂ —à—É–∫–∞—î–º–æ aria-label —Ç–∞ placeholder –≤ input –ø–æ–ª—è—Ö
        inputs = soup.find_all(['input', 'textarea', 'select'])
        for input_elem in inputs:
            # aria-label
            aria_label = input_elem.get('aria-label')
            if aria_label and aria_label.strip():
                instructions.append({
                    'text': aria_label.strip(),
                    'element': 'aria-label',
                    'for': input_elem.get('id', '–Ω–µ–≤—ñ–¥–æ–º–æ')
                })
            
            # placeholder
            placeholder = input_elem.get('placeholder')
            if placeholder and placeholder.strip():
                instructions.append({
                    'text': placeholder.strip(),
                    'element': 'placeholder',
                    'for': input_elem.get('id', '–Ω–µ–≤—ñ–¥–æ–º–æ')
                })
        
        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ –ø—Ä–æ—Å—Ç–∏–π —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç—ñ–≤ –¥–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ
        instruction_texts = [instr['text'] for instr in instructions]
        
        clear_instructions = []
        problematic_instructions = []
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ –∑—Ä–æ–∑—É–º—ñ–ª–æ—Å—Ç—ñ
        from accessibility_evaluator.core.metrics.understandability import UnderstandabilityMetrics
        understandability_metrics = UnderstandabilityMetrics()
        
        for i, instruction_text in enumerate(instruction_texts):
            instruction_obj = instructions[i]
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ü—ñ–Ω–∫–∏
            context = {
                'field_type': self._get_field_type_for_instruction(instruction_obj, html_content),
                'field_id': instruction_obj.get('for')
            }
            
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –º–µ—Ç–æ–¥ –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            is_clear = understandability_metrics._assess_instruction_clarity_with_context(instruction_text, context)
            
            if is_clear:
                clear_instructions.append({
                    'text': instruction_text,
                    'element_type': instruction_obj['element'],
                    'status': '–ó—Ä–æ–∑—É–º—ñ–ª–∞ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è'
                })
            else:
                # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —á–æ–º—É label –Ω–µ–∑—Ä–æ–∑—É–º—ñ–ª–∏–π –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ —Å—Ç—Ä–æ–≥—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó
                issues = self._analyze_instruction_issues_strict(instruction_text)
                
                problematic_instructions.append({
                    'text': instruction_text,
                    'element_type': instruction_obj['element'],
                    'issue': '; '.join(issues) if issues else '–°–∫–ª–∞–¥–Ω–∏–π –¥–ª—è —Ä–æ–∑—É–º—ñ–Ω–Ω—è'
                })
        
        total_instructions = len(instructions)
        clear_count = len(clear_instructions)
        
        if total_instructions > 0:
            score = clear_count / total_instructions
            score_explanation = f"–°–∫–æ—Ä: {clear_count}/{total_instructions} = {score:.3f} (–∞–Ω–∞–ª—ñ–∑ labels –¥–ª—è –ø–æ–ª—ñ–≤ –≤–≤–æ–¥—É)"
        else:
            score_explanation = "Labels –¥–ª—è –ø–æ–ª—ñ–≤ –≤–≤–æ–¥—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
        
        return {
            'total_instructions': total_instructions,
            'clear_instructions': clear_count,
            'problematic_instructions': problematic_instructions,
            'clear_instructions_list': clear_instructions,
            'score_explanation': score_explanation
        }
    
    def _assess_label_clarity(self, text: str, element_type: str) -> bool:
        """–û—Ü—ñ–Ω–∫–∞ –∑—Ä–æ–∑—É–º—ñ–ª–æ—Å—Ç—ñ label –¥–ª—è –ø–æ–ª—è –≤–≤–æ–¥—É –∑ —Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω–∏–º–∏ –∫—Ä–∏—Ç–µ—Ä—ñ—è–º–∏"""
        
        # –ë–∞–∑–æ–≤—ñ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        if len(text.strip()) < 2:
            return False
        
        # –î–ª—è —Ä—ñ–∑–Ω–∏—Ö —Ç–∏–ø—ñ–≤ –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ —Ä—ñ–∑–Ω—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó
        if element_type == 'placeholder':
            # Placeholder –º–æ–∂–µ –±—É—Ç–∏ –∫–æ—Ä–æ—Ç—à–∏–º
            return len(text) <= 50 and len(text.split()) <= 8
        
        if element_type == 'aria-label':
            # aria-label –º–∞—î –±—É—Ç–∏ –∫–æ—Ä–æ—Ç–∫–∏–º —Ç–∞ –∑—Ä–æ–∑—É–º—ñ–ª–∏–º
            return len(text) <= 100 and len(text.split()) <= 15
        
        # –î–ª—è –∑–≤–∏—á–∞–π–Ω–∏—Ö labels
        word_count = len(text.split())
        
        # –†–µ–∞–ª—ñ—Å—Ç–∏—á–Ω—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó –¥–ª—è labels
        basic_criteria = (
            2 <= len(text) <= 100 and           # –†–æ–∑—É–º–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞
            word_count <= 10                    # –ù–µ –±—ñ–ª—å—à–µ 10 —Å–ª—ñ–≤ –¥–ª—è label
        )
        
        if not basic_criteria:
            return False
        
        # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö labels (1-3 —Å–ª–æ–≤–∞) –Ω–µ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Å–∫–ª–∞–¥–Ω—ñ—Å—Ç—å
        if word_count <= 3:
            return True
        
        # –î–ª—è –¥–æ–≤—à–∏—Ö labels –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏—Ç–∞–±–µ–ª—å–Ω—ñ—Å—Ç—å –∑ –º'—è–∫—à–∏–º–∏ –∫—Ä–∏—Ç–µ—Ä—ñ—è–º–∏
        try:
            import textstat
            flesch_score = textstat.flesch_reading_ease(text)
            grade_level = textstat.flesch_kincaid_grade(text)
            
            # –ú'—è–∫—à—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó –¥–ª—è labels
            readability_ok = (
                flesch_score >= 30 or           # –ó–Ω–∞—á–Ω–æ –º'—è–∫—à–∏–π –∫—Ä–∏—Ç–µ—Ä—ñ–π
                grade_level <= 12               # –î–æ 12 –∫–ª–∞—Å—É –∑–∞–º—ñ—Å—Ç—å 8
            )
            
            return readability_ok
            
        except Exception:
            # –Ø–∫—â–æ –Ω–µ –º–æ–∂–µ–º–æ –æ—Ü—ñ–Ω–∏—Ç–∏ - –≤–≤–∞–∂–∞—î–º–æ –∑—Ä–æ–∑—É–º—ñ–ª–∏–º –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç—ñ–≤
            return word_count <= 6
    
    def _analyze_label_issues(self, text: str, element_type: str) -> list:
        """–ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–±–ª–µ–º –∑ label"""
        
        issues = []
        word_count = len(text.split())
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–æ–≤–∂–∏–Ω–∏
        if element_type == 'placeholder' and len(text) > 50:
            issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–∏–π placeholder ({len(text)} —Å–∏–º–≤–æ–ª—ñ–≤)")
        elif element_type == 'aria-label' and len(text) > 100:
            issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–∏–π aria-label ({len(text)} —Å–∏–º–≤–æ–ª—ñ–≤)")
        elif element_type == 'label' and len(text) > 100:
            issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–∏–π label ({len(text)} —Å–∏–º–≤–æ–ª—ñ–≤)")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —Å–ª—ñ–≤
        if element_type == 'placeholder' and word_count > 8:
            issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –±–∞–≥–∞—Ç–æ —Å–ª—ñ–≤ —É placeholder ({word_count} —Å–ª—ñ–≤)")
        elif element_type == 'aria-label' and word_count > 15:
            issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –±–∞–≥–∞—Ç–æ —Å–ª—ñ–≤ —É aria-label ({word_count} —Å–ª—ñ–≤)")
        elif element_type == 'label' and word_count > 10:
            issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –±–∞–≥–∞—Ç–æ —Å–ª—ñ–≤ —É label ({word_count} —Å–ª—ñ–≤)")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—ñ —Ç—ñ–ª—å–∫–∏ –¥–ª—è –¥–æ–≤—à–∏—Ö —Ç–µ–∫—Å—Ç—ñ–≤
        if word_count > 3:
            try:
                import textstat
                flesch_score = textstat.flesch_reading_ease(text)
                grade_level = textstat.flesch_kincaid_grade(text)
                
                if flesch_score < 30:  # –î—É–∂–µ –º'—è–∫–∏–π –∫—Ä–∏—Ç–µ—Ä—ñ–π
                    issues.append(f"–î—É–∂–µ –Ω–∏–∑—å–∫–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω—ñ—Å—Ç—å (Flesch: {flesch_score:.1f})")
                elif grade_level > 12:  # –î–æ 12 –∫–ª–∞—Å—É
                    issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ —Å–∫–ª–∞–¥–Ω–∏–π (—Ä—ñ–≤–µ–Ω—å: {grade_level:.1f} –∫–ª–∞—Å)")
                    
            except Exception:
                pass
        
        return issues
    
    def _analyze_instruction_issues_strict(self, text: str) -> list:
        """–ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–±–ª–µ–º –∑ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—î—é –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ –∞–¥–∞–ø—Ç–æ–≤–∞–Ω—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó –∑ UnderstandabilityMetrics"""
        
        issues = []
        
        # –ë–∞–∑–æ–≤—ñ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        if len(text.strip()) < 2:
            issues.append("–ó–∞–Ω–∞–¥—Ç–æ –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç (–º–µ–Ω—à–µ 2 —Å–∏–º–≤–æ–ª—ñ–≤)")
            return issues
            
        if len(text) > 200:
            issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–∏–π —Ç–µ–∫—Å—Ç ({len(text)} —Å–∏–º–≤–æ–ª—ñ–≤, –º–∞–∫—Å–∏–º—É–º 200)")
        
        word_count = len(text.split())
        sentence_count = len(re.split(r'[.!?]+', text.strip()))
        
        if word_count > 25:
            issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –±–∞–≥–∞—Ç–æ —Å–ª—ñ–≤ ({word_count}, –º–∞–∫—Å–∏–º—É–º 25)")
            
        if sentence_count > 3:
            issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –±–∞–≥–∞—Ç–æ —Ä–µ—á–µ–Ω—å ({sentence_count}, –º–∞–∫—Å–∏–º—É–º 3)")
        
        # –ê–Ω–∞–ª—ñ–∑ –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ –¥–æ–≤–∂–∏–Ω–∏ —Ç–µ–∫—Å—Ç—É
        if word_count <= 3:
            # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç—ñ–≤ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Å–∫–ª–∞–¥–Ω—ñ —Ç–µ—Ä–º—ñ–Ω–∏
            if not self._is_simple_short_text_evaluator(text):
                issues.append("–ú—ñ—Å—Ç–∏—Ç—å —Å–∫–ª–∞–¥–Ω—ñ —Ç–µ—Ö–Ω—ñ—á–Ω—ñ —Ç–µ—Ä–º—ñ–Ω–∏")
        elif word_count <= 8:
            # –î–ª—è —Å–µ—Ä–µ–¥–Ω—ñ—Ö —Ç–µ–∫—Å—Ç—ñ–≤ –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–æ–¥–∞—Ç–∫–æ–≤—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó
            if not self._is_simple_short_text_evaluator(text):
                issues.append("–ú—ñ—Å—Ç–∏—Ç—å —Å–∫–ª–∞–¥–Ω—ñ —Ç–µ—Ö–Ω—ñ—á–Ω—ñ —Ç–µ—Ä–º—ñ–Ω–∏")
            
            words = text.split()
            avg_word_length = sum(len(word) for word in words) / len(words)
            if avg_word_length > 8:
                issues.append(f"–°–µ—Ä–µ–¥–Ω—è –¥–æ–≤–∂–∏–Ω–∞ —Å–ª—ñ–≤ –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∞ ({avg_word_length:.1f}, –º–∞–∫—Å–∏–º—É–º 8)")
            
            complex_words = [word for word in words if len(word) > 8]
            if len(complex_words) > 1:
                issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ –±–∞–≥–∞—Ç–æ —Å–∫–ª–∞–¥–Ω–∏—Ö —Å–ª—ñ–≤ ({len(complex_words)}, –º–∞–∫—Å–∏–º—É–º 1)")
        else:
            # –î–ª—è –¥–æ–≤—à–∏—Ö —Ç–µ–∫—Å—Ç—ñ–≤ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ textstat –∑ –º'—è–∫—à–∏–º–∏ –∫—Ä–∏—Ç–µ—Ä—ñ—è–º–∏
            try:
                import textstat
                flesch_score = textstat.flesch_reading_ease(text)
                grade_level = textstat.flesch_kincaid_grade(text)
                ari_score = textstat.automated_readability_index(text)
                
                # –ú'—è–∫—à—ñ –∫—Ä–∏—Ç–µ—Ä—ñ—ó
                if flesch_score < 30:
                    issues.append(f"–î—É–∂–µ –Ω–∏–∑—å–∫–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω—ñ—Å—Ç—å (Flesch: {flesch_score:.1f}, –ø–æ—Ç—Ä—ñ–±–Ω–æ >= 30)")
                    
                if grade_level > 10:
                    issues.append(f"–ó–∞–Ω–∞–¥—Ç–æ —Å–∫–ª–∞–¥–Ω–∏–π —Ä—ñ–≤–µ–Ω—å (Grade: {grade_level:.1f}, –ø–æ—Ç—Ä—ñ–±–Ω–æ <= 10)")
                    
                if ari_score > 10:
                    issues.append(f"–í–∏—Å–æ–∫–∏–π ARI —ñ–Ω–¥–µ–∫—Å ({ari_score:.1f}, –ø–æ—Ç—Ä—ñ–±–Ω–æ <= 10)")
                    
            except Exception:
                issues.append("–ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–≤–∞—Ç–∏ —á–∏—Ç–∞–±–µ–ª—å–Ω—ñ—Å—Ç—å")
        
        return issues
    
    def _is_simple_short_text_evaluator(self, text: str) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ—Å—Ç–∏—Ö –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç—ñ–≤ –¥–ª—è evaluator.py"""
        
        # –°–ø–∏—Å–æ–∫ —Å–∫–ª–∞–¥–Ω–∏—Ö/—Ç–µ—Ö–Ω—ñ—á–Ω–∏—Ö —Ç–µ—Ä–º—ñ–Ω—ñ–≤
        complex_terms = [
            '–¥–µ—Å–∫—Ä–∏–ø—Ç–∏–≤–Ω–∏–π', '—ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—è', '—É–∑–∞–≥–∞–ª—å–Ω–µ–Ω–∏–π', '—Å—É–± º—î–∫—Ç', '–ø–∞—Ä–∞–º–µ—Ç—Ä',
            '–∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è', '–∞—É—Ç–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—è', '–∞–≤—Ç–æ—Ä–∏–∑–∞—Ü—ñ—è', '–≤–∞–ª—ñ–¥–∞—Ü—ñ—è', '–≤–µ—Ä–∏—Ñ—ñ–∫–∞—Ü—ñ—è',
            '—ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è', '—ñ–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü—ñ—è', '–æ–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è', '—Å–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—è', '–º–æ–¥–∏—Ñ—ñ–∫–∞—Ü—ñ—è'
        ]
        
        text_lower = text.lower()
        
        # –Ø–∫—â–æ –º—ñ—Å—Ç–∏—Ç—å —Å–∫–ª–∞–¥–Ω—ñ —Ç–µ—Ä–º—ñ–Ω–∏ - –Ω–µ–∑—Ä–æ–∑—É–º—ñ–ª–∏–π
        for term in complex_terms:
            if term in text_lower:
                return False
        
        # –Ø–∫—â–æ –¥–æ–≤–∂–∏–Ω–∞ —Å–ª–æ–≤–∞ –±—ñ–ª—å—à–µ 12 —Å–∏–º–≤–æ–ª—ñ–≤ - –º–æ–∂–µ –±—É—Ç–∏ —Å–∫–ª–∞–¥–Ω–∏–º
        words = text.split()
        for word in words:
            if len(word) > 12:
                return False
        
        return True
    
    def _get_field_type_for_instruction(self, instruction_obj: Dict[str, Any], html_content: str) -> str:
        """–í–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ç–∏–ø—É –ø–æ–ª—è –¥–ª—è —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó"""
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        element_type = instruction_obj.get('element', '')
        field_id = instruction_obj.get('for')
        
        # –î–ª—è label —à—É–∫–∞—î–º–æ –ø–æ–≤'—è–∑–∞–Ω–µ –ø–æ–ª–µ
        if element_type == 'label' and field_id:
            field = soup.find(id=field_id)
            if field:
                return field.get('type', field.name)
        
        # –î–ª—è placeholder —Ç–∞ aria-label —Ç–∏–ø –≤–∂–µ –≤—ñ–¥–æ–º–∏–π –∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –∑–±–æ—Ä—É
        # –ê–ª–µ —è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ, –º–æ–∂–µ–º–æ –∑–Ω–∞–π—Ç–∏ –µ–ª–µ–º–µ–Ω—Ç –∑–∞ —Ç–µ–∫—Å—Ç–æ–º
        if element_type in ['placeholder', 'aria-label']:
            # –®—É–∫–∞—î–º–æ input –∑ —Ç–∞–∫–∏–º placeholder –∞–±–æ aria-label
            text = instruction_obj.get('text', '')
            
            if element_type == 'placeholder':
                field = soup.find(['input', 'textarea'], placeholder=text)
            else:  # aria-label
                field = soup.find(['input', 'textarea'], attrs={'aria-label': text})
            
            if field:
                return field.get('type', field.name)
        
        return 'unknown'
    
    def _analyze_input_assistance_details(self, page_data: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –¥–æ–ø–æ–º–æ–≥–∏ –ø—Ä–∏ –≤–≤–µ–¥–µ–Ω–Ω—ñ"""
        
        html_content = page_data.get('html_content', '')
        
        # –í–∏—Ç—è–≥—É—î–º–æ –ø–æ–ª—è –≤–≤–æ–¥—É –∑ HTML —Å–∞–º–æ—Å—Ç—ñ–π–Ω–æ
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –¢–∏–ø–∏ input –ø–æ–ª—ñ–≤, —è–∫—ñ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –¥–æ–ø–æ–º–æ–≥–∏ –ø—Ä–∏ –≤–≤–µ–¥–µ–Ω–Ω—ñ
        text_input_types = [
            'text', 'email', 'password', 'tel', 'url', 'search', 
            'number', 'date', 'datetime-local', 'month', 'week', 'time'
        ]
        
        # –®—É–∫–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –∑–≤–∏—á–∞–π–Ω—ñ input –ø–æ–ª—è —Ç–∞ textarea (–Ω–µ select, checkbox, radio)
        input_elements = soup.find_all(['input', 'textarea'])
        
        fields = []
        for element in input_elements:
            # –î–ª—è input –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ç–∏–ø
            if element.name == 'input':
                input_type = element.get('type', 'text').lower()
                # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ checkbox, radio, submit, button —Ç–æ—â–æ
                if input_type not in text_input_types:
                    continue
            
            # –î–ª—è textarea –∑–∞–≤–∂–¥–∏ –≤—Ä–∞—Ö–æ–≤—É—î–º–æ
            field_info = {
                'selector': f"{element.name}[type='{element.get('type', 'text')}']" if element.name == 'input' else element.name,
                'html': str(element),
                'type': element.get('type', 'text'),
                'placeholder': element.get('placeholder'),
                'autocomplete': element.get('autocomplete'),
                'aria_label': element.get('aria-label'),
                'aria_describedby': element.get('aria-describedby'),
                'title': element.get('title')
            }
            fields.append(field_info)
        
        assisted_fields = []
        problematic_fields = []
        
        for field in fields:
            has_assistance = (
                field.get('autocomplete') or
                field.get('placeholder') or
                field.get('aria_describedby') or
                field.get('aria_label') or
                field.get('title')
            )
            
            if has_assistance:
                assistance_types = []
                if field.get('placeholder'):
                    assistance_types.append(f"placeholder='{field['placeholder']}'")
                if field.get('autocomplete'):
                    assistance_types.append(f"autocomplete='{field['autocomplete']}'")
                if field.get('aria_label'):
                    assistance_types.append(f"aria-label='{field['aria_label']}'")
                if field.get('title'):
                    assistance_types.append(f"title='{field['title']}'")
                if field.get('aria_describedby'):
                    assistance_types.append(f"aria-describedby='{field['aria_describedby']}'")
                
                assisted_fields.append({
                    'selector': field.get('selector', '–Ω–µ–≤—ñ–¥–æ–º–æ'),
                    'html': field.get('html', ''),
                    'assistance': '; '.join(assistance_types)
                })
            else:
                problematic_fields.append({
                    'selector': field.get('selector', '–Ω–µ–≤—ñ–¥–æ–º–æ'),
                    'html': field.get('html', ''),
                    'type': field.get('type', 'text'),
                    'issue': '–í—ñ–¥—Å—É—Ç–Ω—ñ –ø—ñ–¥–∫–∞–∑–∫–∏ (placeholder, autocomplete, aria-label, title)'
                })
        
        total_fields = len(fields)
        assisted_count = len(assisted_fields)
        
        if total_fields > 0:
            score = assisted_count / total_fields
            score_explanation = f"–°–∫–æ—Ä: {assisted_count}/{total_fields} = {score:.3f} (–∞–Ω–∞–ª—ñ–∑ —Ç—ñ–ª—å–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –ø–æ–ª—ñ–≤: input[text,email,password,etc] —Ç–∞ textarea)"
        else:
            score_explanation = "–¢–µ–∫—Å—Ç–æ–≤—ñ –ø–æ–ª—è –≤–≤–æ–¥—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ (checkbox, radio, select –Ω–µ –≤—Ä–∞—Ö–æ–≤—É—é—Ç—å—Å—è)"
        
        return {
            'total_fields': total_fields,
            'assisted_fields': assisted_count,
            'problematic_fields': problematic_fields,
            'assisted_fields_list': assisted_fields,
            'score_explanation': score_explanation
        }
    
    def _analyze_error_support_details(self, page_data: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –ø–æ–º–∏–ª–æ–∫ –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º –≥—ñ–±—Ä–∏–¥–Ω–æ—ó –ª–æ–≥—ñ–∫–∏ (—Å—Ç–∞—Ç–∏—á–Ω–∏–π + –¥–∏–Ω–∞–º—ñ—á–Ω–∏–π)"""
        
        html_content = page_data.get('html_content', '')
        form_error_test_results = page_data.get('form_error_test_results', [])
        
        if not html_content:
            return {
                'total_forms': 0,
                'supported_forms': 0,
                'problematic_forms': [],
                'supported_forms_list': [],
                'score_explanation': "HTML –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π",
                'analysis_type': 'error'
            }
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ —Ñ–æ—Ä–º–∏
        forms = soup.find_all('form')
        if not forms:
            # –Ø–∫—â–æ –Ω–µ–º–∞—î —Ñ–æ—Ä–º, —à—É–∫–∞—î–º–æ –æ–∫—Ä–µ–º—ñ –ø–æ–ª—è
            individual_fields = soup.find_all(['input', 'textarea', 'select'])
            if individual_fields:
                # –û–±—Ä–æ–±–ª—è—î–º–æ —è–∫ –æ–¥–Ω—É –≤—ñ—Ä—Ç—É–∞–ª—å–Ω—É —Ñ–æ—Ä–º—É
                forms = [soup]  # –í—Å—è —Å—Ç–æ—Ä—ñ–Ω–∫–∞ —è–∫ –æ–¥–Ω–∞ —Ñ–æ—Ä–º–∞
            else:
                return {
                    'total_forms': 0,
                    'supported_forms': 0,
                    'problematic_forms': [],
                    'supported_forms_list': [],
                    'score_explanation': "–ü–æ–ª—è –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ",
                    'analysis_type': 'no_forms'
                }
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ UnderstandabilityMetrics –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
        from accessibility_evaluator.core.metrics.understandability import UnderstandabilityMetrics
        understandability_metrics = UnderstandabilityMetrics()
        
        supported_forms = []
        problematic_forms = []
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Ç–∏–ø –∞–Ω–∞–ª—ñ–∑—É
        has_dynamic_results = len(form_error_test_results) > 0
        analysis_type = 'hybrid' if has_dynamic_results else 'static_only'
        
        for i, form in enumerate(forms, 1):
            # –°—Ç–∞—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Ñ–æ—Ä–º–∏
            static_form_quality = understandability_metrics._analyze_form_error_support_quality(form, html_content)
            
            # –î–∏–Ω–∞–º—ñ—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ (—è–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∏–π)
            dynamic_test_result = None
            dynamic_form_quality = 0.0
            
            if has_dynamic_results and i <= len(form_error_test_results):
                dynamic_test_result = form_error_test_results[i-1]
                if 'error' not in dynamic_test_result:
                    dynamic_form_quality = dynamic_test_result.get('quality_score', 0.0)
            
            # –ö–æ–º–±—ñ–Ω–æ–≤–∞–Ω–∏–π —Å–∫–æ—Ä (—è–∫—â–æ —î –¥–∏–Ω–∞–º—ñ—á–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏)
            if dynamic_test_result and 'error' not in dynamic_test_result:
                combined_quality = (static_form_quality * 0.4) + (dynamic_form_quality * 0.6)
            else:
                combined_quality = static_form_quality
            
            # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –ø–æ–ª—è –≤ —Ñ–æ—Ä–º—ñ
            fields = form.find_all(['input', 'textarea', 'select'])
            validatable_fields = [field for field in fields if understandability_metrics._field_needs_validation(field)]
            
            if not validatable_fields:
                # –§–æ—Ä–º–∞ –±–µ–∑ –ø–æ–ª—ñ–≤ –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
                supported_forms.append({
                    'selector': f'form#{i}' if len(forms) > 1 else 'form',
                    'html': str(form)[:200] + '...' if len(str(form)) > 200 else str(form),
                    'quality_score': 1.0,
                    'static_quality': 1.0,
                    'dynamic_quality': 1.0 if dynamic_test_result else None,
                    'features': '–ù–µ–º–∞—î –ø–æ–ª—ñ–≤ —â–æ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó',
                    'field_details': [],
                    'dynamic_test_result': dynamic_test_result
                })
                continue
            
            # –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –ø–æ–ª—ñ–≤
            field_details = []
            for field in validatable_fields:
                field_quality = understandability_metrics._analyze_field_error_support(field, html_content)
                
                # –§–∞–∑–æ–≤–∏–π –∞–Ω–∞–ª—ñ–∑
                phase1_score = understandability_metrics._phase1_basic_error_support(field, html_content)
                phase2_score = understandability_metrics._phase2_message_quality(field, html_content)
                phase3_score = understandability_metrics._phase3_dynamic_validation(field, html_content)
                
                field_name = field.get('name') or field.get('id') or f"{field.name}[{field.get('type', 'unknown')}]"
                
                field_detail = {
                    'name': field_name,
                    'type': field.get('type', field.name),
                    'quality_score': field_quality,
                    'phase1_score': phase1_score,
                    'phase2_score': phase2_score,
                    'phase3_score': phase3_score,
                    'selector': self._generate_field_selector(field),
                    'html': str(field)[:100] + '...' if len(str(field)) > 100 else str(field),
                    'features': self._get_field_error_features_detailed(field, html_content, understandability_metrics)
                }
                
                field_details.append(field_detail)
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –¥–µ—Ç–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ–æ—Ä–º—É
            form_info = {
                'selector': f'form#{i}' if len(forms) > 1 else 'form',
                'html': str(form)[:200] + '...' if len(str(form)) > 200 else str(form),
                'quality_score': combined_quality,
                'static_quality': static_form_quality,
                'dynamic_quality': dynamic_form_quality if dynamic_test_result and 'error' not in dynamic_test_result else None,
                'field_details': field_details,
                'dynamic_test_result': dynamic_test_result
            }
            
            # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –¥–∏–Ω–∞–º—ñ—á–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
            if dynamic_test_result:
                if 'error' in dynamic_test_result:
                    form_info['dynamic_error'] = dynamic_test_result['error']
                else:
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–≤–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É
                    form_info['dynamic_test_result'] = dynamic_test_result
                    
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Å—Ç–∞—Ä–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å—É–º—ñ—Å–Ω–æ—Å—Ç—ñ
                    if dynamic_test_result.get('systematic_analysis'):
                        # –ù–æ–≤–∏–π —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
                        form_info['dynamic_features'] = f"–°–∏—Å—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑: {dynamic_test_result.get('supported_fields', 0)}/{dynamic_test_result.get('total_fields', 0)} –ø–æ–ª—ñ–≤"
                    else:
                        # –°—Ç–∞—Ä–∏–π —Ñ–æ—Ä–º–∞—Ç
                        form_info['dynamic_breakdown'] = dynamic_test_result.get('detailed_breakdown', {})
                        form_info['dynamic_features'] = self._summarize_dynamic_features(dynamic_test_result)
            
            # –í–∏–∑–Ω–∞—á–∞—î–º–æ —á–∏ —Ñ–æ—Ä–º–∞ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è
            if combined_quality >= 0.5:  # –ü–æ—Ä—ñ–≥ –¥–ª—è "–ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è"
                features_summary = self._summarize_hybrid_form_features(field_details, dynamic_test_result)
                form_info['features'] = features_summary
                supported_forms.append(form_info)
            else:
                issues = self._identify_hybrid_form_issues(field_details, combined_quality, dynamic_test_result)
                form_info['issue'] = '; '.join(issues)
                problematic_forms.append(form_info)
        
        total_forms = len(forms)
        supported_count = len(supported_forms)
        
        if total_forms > 0:
            score = supported_count / total_forms
            if analysis_type == 'hybrid':
                score_explanation = f"–ì—ñ–±—Ä–∏–¥–Ω–∏–π —Å–∫–æ—Ä: {supported_count}/{total_forms} = {score:.3f} (—Å—Ç–∞—Ç–∏—á–Ω–∏–π + –¥–∏–Ω–∞–º—ñ—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑)"
            else:
                score_explanation = f"–°—Ç–∞—Ç–∏—á–Ω–∏–π —Å–∫–æ—Ä: {supported_count}/{total_forms} = {score:.3f} (–¥–∏–Ω–∞–º—ñ—á–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–µ)"
        else:
            score_explanation = "–§–æ—Ä–º–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
        
        return {
            'total_forms': total_forms,
            'supported_forms': supported_count,
            'problematic_forms': problematic_forms,
            'supported_forms_list': supported_forms,
            'score_explanation': score_explanation,
            'analysis_type': analysis_type,
            'dynamic_tests_count': len(form_error_test_results)
        }
    
    def _analyze_media_details(self, page_data: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ –º–µ–¥—ñ–∞ –≤–∫–ª—é—á–Ω–æ –∑ embedded –≤—ñ–¥–µ–æ"""
        
        media_elements = page_data.get('media_elements', [])
        video_elements = [elem for elem in media_elements if elem['type'] in ['video', 'embedded_video']]
        
        details = {
            'total_media': len(video_elements),
            'accessible_media': 0,
            'problematic_media': [],
            'accessible_media_list': [],
            'score_explanation': ''
        }
        
        if not video_elements:
            details['score_explanation'] = "–í—ñ–¥–µ–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
            return details
        
        for video in video_elements:
            video_type = video.get('type', 'unknown')
            platform = video.get('platform', 'native')
            src = video.get('src') or ''
            
            selector = f"iframe[src*='{platform}']" if video_type == 'embedded_video' else 'video'
            
            video_info = {
                'type': video_type,
                'platform': platform,
                'src': src,
                'title': video.get('title', '–ë–µ–∑ –Ω–∞–∑–≤–∏'),
                'selector': selector,
                'html': f"<{selector} src=\"{src[:50]}...\">" if src and len(src) > 50 else f"<{selector} src=\"{src}\">"
            }
            
            has_accessibility = False
            accessibility_features = []
            
            if video_type == 'video':
                # –ù–∞—Ç–∏–≤–Ω–µ HTML5 –≤—ñ–¥–µ–æ
                tracks = video.get('tracks', [])
                
                for track in tracks:
                    track_kind = track.get('kind', '')
                    if track_kind in ['subtitles', 'captions']:
                        has_accessibility = True
                        accessibility_features.append(f"–°—É–±—Ç–∏—Ç—Ä–∏ ({track_kind})")
                    elif track_kind == 'descriptions':
                        has_accessibility = True
                        accessibility_features.append("–ê—É–¥—ñ–æ–æ–ø–∏—Å–∏")
            
            elif video_type == 'embedded_video':
                # Embedded –≤—ñ–¥–µ–æ
                has_captions = video.get('has_captions', False)
                caption_check_method = video.get('caption_check_method', 'url_params')
                
                if has_captions:
                    has_accessibility = True
                    if caption_check_method == 'youtube_api':
                        accessibility_features.append(f"–°—É–±—Ç–∏—Ç—Ä–∏ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω—ñ YouTube API ({platform})")
                    elif caption_check_method == 'enhanced_url_analysis':
                        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î —è–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤
                        if any(param in src for param in ['cc_load_policy=1', 'captions=1', 'cc_lang_pref=']):
                            accessibility_features.append(f"–°—É–±—Ç–∏—Ç—Ä–∏ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ URL ({platform})")
                        elif any(param in src for param in ['hl=en', 'hl=uk', 'hl=ru', 'hl=de', 'hl=fr']):
                            accessibility_features.append(f"–ô–º–æ–≤—ñ—Ä–Ω—ñ –∞–≤—Ç–æ—Å—É–±—Ç–∏—Ç—Ä–∏ –∑–∞ –º–æ–≤–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ ({platform})")
                        else:
                            accessibility_features.append(f"–ô–º–æ–≤—ñ—Ä–Ω—ñ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ —Å—É–±—Ç–∏—Ç—Ä–∏ YouTube (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥–µ–æ)")
                    else:
                        accessibility_features.append(f"–°—É–±—Ç–∏—Ç—Ä–∏ –≤ URL ({platform})")
            
            if has_accessibility:
                video_info['status'] = f"–î–æ—Å—Ç—É–ø–Ω–µ: {', '.join(accessibility_features)}"
                details['accessible_media_list'].append(video_info)
                details['accessible_media'] += 1
            else:
                video_info['issue'] = "–í—ñ–¥—Å—É—Ç–Ω—ñ —Å—É–±—Ç–∏—Ç—Ä–∏ —Ç–∞ –∞—É–¥—ñ–æ–æ–ø–∏—Å–∏"
                details['problematic_media'].append(video_info)
        
        if details['total_media'] > 0:
            score = details['accessible_media'] / details['total_media']
            details['score_explanation'] = f"–°–∫–æ—Ä: {details['accessible_media']}/{details['total_media']} = {score:.3f} (–∞–Ω–∞–ª—ñ–∑ –Ω–∞—Ç–∏–≤–Ω–∏—Ö —Ç–∞ embedded –≤—ñ–¥–µ–æ)"
        else:
            details['score_explanation'] = "–í—ñ–¥–µ–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"
        
        return details
    
    def _analyze_form_fields_error_support(self, form, html_content: str) -> list:
        """–ê–Ω–∞–ª—ñ–∑ –ø–æ–ª—ñ–≤ —Ñ–æ—Ä–º–∏ –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∑–≤—ñ—Ç—É"""
        
        fields = form.find_all(['input', 'textarea', 'select'])
        field_details = []
        
        from accessibility_evaluator.core.metrics.understandability import UnderstandabilityMetrics
        metrics = UnderstandabilityMetrics()
        
        for field in fields:
            if metrics._field_needs_validation(field):
                field_quality = metrics._analyze_field_error_support(field, html_content)
                
                field_info = {
                    'name': field.get('name') or field.get('id') or 'unnamed',
                    'type': field.get('type', field.name),
                    'quality_score': field_quality,
                    'selector': self._generate_field_selector(field),
                    'html': str(field)[:100] + '...' if len(str(field)) > 100 else str(field),
                    'error_support_features': self._get_field_error_features(field, html_content)
                }
                
                field_details.append(field_info)
        
        return field_details
    
    def _generate_field_selector(self, field) -> str:
        """–ì–µ–Ω–µ—Ä—É—î CSS —Å–µ–ª–µ–∫—Ç–æ—Ä –¥–ª—è –ø–æ–ª—è"""
        
        if field_id := field.get('id'):
            return f'#{field_id}'
        elif field_name := field.get('name'):
            return f'[name="{field_name}"]'
        else:
            field_type = field.get('type', field.name)
            return f'{field.name}[type="{field_type}"]'
    
    def _get_field_error_features(self, field, html_content: str) -> dict:
        """–û—Ç—Ä–∏–º—É—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ—É–Ω–∫—Ü—ñ—ó –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –ø–æ–º–∏–ª–æ–∫ –ø–æ–ª—è"""
        
        features = {
            'validation': [],
            'error_messages': [],
            'accessibility': [],
            'dynamic': []
        }
        
        # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
        if field.get('required') is not None:
            features['validation'].append('required')
        if field.get('pattern'):
            features['validation'].append(f'pattern: {field.get("pattern")}')
        
        # Accessibility
        if field.get('aria-invalid'):
            features['accessibility'].append(f'aria-invalid: {field.get("aria-invalid")}')
        if field.get('aria-describedby'):
            features['accessibility'].append(f'aria-describedby: {field.get("aria-describedby")}')
        
        # Error messages
        from accessibility_evaluator.core.metrics.understandability import UnderstandabilityMetrics
        metrics = UnderstandabilityMetrics()
        error_messages = metrics._find_error_messages_for_field(field, html_content)
        features['error_messages'] = error_messages
        
        # Dynamic features
        if metrics._detect_javascript_validation(field, html_content):
            features['dynamic'].append('JavaScript validation detected')
        if metrics._check_live_regions_exist(html_content):
            features['dynamic'].append('Live regions present')
        
        return features
    
    def _get_field_error_features_detailed(self, field, html_content: str, understandability_metrics) -> Dict[str, Any]:
        """–û—Ç—Ä–∏–º—É—î –¥–µ—Ç–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Ñ—É–Ω–∫—Ü—ñ—ó –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –ø–æ–º–∏–ª–æ–∫ –ø–æ–ª—è –∑ —Ñ–∞–∑–æ–≤–∏–º –∞–Ω–∞–ª—ñ–∑–æ–º –¥–ª—è UI"""
        
        # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ —Ñ–∞–∫—Ç–∏—á–Ω—ñ —Å–∫–æ—Ä–∏
        phase1_score = understandability_metrics._phase1_basic_error_support(field, html_content)
        phase2_score = understandability_metrics._phase2_message_quality(field, html_content)
        phase3_score = understandability_metrics._phase3_dynamic_validation(field, html_content)
        
        # –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∫–æ–∂–Ω–æ—ó —Ñ–∞–∑–∏
        phase1_details = self._analyze_phase1_details(field, html_content, understandability_metrics)
        phase2_details = self._analyze_phase2_details(field, html_content, understandability_metrics)
        phase3_details = self._analyze_phase3_details(field, html_content, understandability_metrics)
        
        return {
            'phase1': {
                'score': phase1_score,
                'max_score': 0.4,
                'title': '–§–∞–∑–∞ 1: –ë–∞–∑–æ–≤—ñ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è',
                'description': '–û—Å–Ω–æ–≤–Ω—ñ –∞—Ç—Ä–∏–±—É—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ —Ç–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó',
                'details': phase1_details,
                'explanation': self._get_phase1_explanation()
            },
            'phase2': {
                'score': phase2_score,
                'max_score': 0.3,
                'title': '–§–∞–∑–∞ 2: –Ø–∫—ñ—Å—Ç—å –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å',
                'description': '–ó—Ä–æ–∑—É–º—ñ–ª—ñ —Ç–∞ –∫–æ—Ä–∏—Å–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏',
                'details': phase2_details,
                'explanation': self._get_phase2_explanation()
            },
            'phase3': {
                'score': phase3_score,
                'max_score': 0.3,
                'title': '–§–∞–∑–∞ 3: –î–∏–Ω–∞–º—ñ—á–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è',
                'description': '–Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è —Ç–∞ live –æ–Ω–æ–≤–ª–µ–Ω–Ω—è',
                'details': phase3_details,
                'explanation': self._get_phase3_explanation()
            }
        }
    
    def _analyze_phase1_details(self, field, html_content: str, understandability_metrics) -> List[Dict[str, Any]]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –§–∞–∑–∏ 1 –¥–ª—è UI"""
        
        details = []
        
        # 1. –í–∞–ª—ñ–¥–∞—Ü—ñ—è (required/pattern) - 0.1
        has_required = field.get('required') is not None
        has_pattern = field.get('pattern') is not None
        
        if has_required or has_pattern:
            validation_types = []
            if has_required:
                validation_types.append('required')
            if has_pattern:
                validation_types.append(f'pattern="{field.get("pattern")}"')
            
            details.append({
                'feature': '–í–∞–ª—ñ–¥–∞—Ü—ñ—è',
                'status': 'success',
                'score': 0.1,
                'description': f'HTML5 –≤–∞–ª—ñ–¥–∞—Ü—ñ—è: {", ".join(validation_types)}',
                'explanation': '–ë—Ä–∞—É–∑–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –ø–µ—Ä–µ–≤—ñ—Ä—è—î –ø—Ä–∞–≤–∏–ª—å–Ω—ñ—Å—Ç—å –≤–≤–µ–¥–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö'
            })
        else:
            details.append({
                'feature': '–í–∞–ª—ñ–¥–∞—Ü—ñ—è',
                'status': 'missing',
                'score': 0.0,
                'description': '–í—ñ–¥—Å—É—Ç–Ω—ñ –∞—Ç—Ä–∏–±—É—Ç–∏ required –∞–±–æ pattern',
                'explanation': '–î–æ–¥–∞–π—Ç–µ required –¥–ª—è –æ–±–æ–≤\'—è–∑–∫–æ–≤–∏—Ö –ø–æ–ª—ñ–≤ –∞–±–æ pattern –¥–ª—è —Ñ–æ—Ä–º–∞—Ç—É'
            })
        
        # 2. aria-invalid - 0.1
        has_aria_invalid = bool(field.get('aria-invalid'))
        if has_aria_invalid:
            aria_value = field.get('aria-invalid')
            details.append({
                'feature': 'aria-invalid',
                'status': 'success',
                'score': 0.1,
                'description': f'aria-invalid="{aria_value}"',
                'explanation': '–°–∫—Ä—ñ–Ω-—Ä—ñ–¥–µ—Ä–∏ –ø–æ–≤—ñ–¥–æ–º–ª—è—é—Ç—å –ø—Ä–æ —Å—Ç–∞–Ω –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –ø–æ–ª—è'
            })
        else:
            details.append({
                'feature': 'aria-invalid',
                'status': 'missing',
                'score': 0.0,
                'description': '–í—ñ–¥—Å—É—Ç–Ω—ñ–π –∞—Ç—Ä–∏–±—É—Ç aria-invalid',
                'explanation': '–î–æ–¥–∞–π—Ç–µ aria-invalid="false" (–∞–±–æ "true" –ø—Ä–∏ –ø–æ–º–∏–ª—Ü—ñ) –¥–ª—è —Å–∫—Ä—ñ–Ω-—Ä—ñ–¥–µ—Ä—ñ–≤'
            })
        
        # 3. aria-describedby –∑–≤'—è–∑–æ–∫ - 0.1
        aria_describedby = field.get('aria-describedby')
        if aria_describedby:
            exists = understandability_metrics._check_aria_describedby_exists(aria_describedby, html_content)
            if exists:
                details.append({
                    'feature': 'aria-describedby',
                    'status': 'success',
                    'score': 0.1,
                    'description': f'–ó–≤\'—è–∑–∞–Ω–æ –∑ –µ–ª–µ–º–µ–Ω—Ç–æ–º: {aria_describedby}',
                    'explanation': '–°–∫—Ä—ñ–Ω-—Ä—ñ–¥–µ—Ä–∏ –∑–∞—á–∏—Ç–∞—é—Ç—å –ø–æ–≤\'—è–∑–∞–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É'
                })
            else:
                details.append({
                    'feature': 'aria-describedby',
                    'status': 'error',
                    'score': 0.0,
                    'description': f'–ï–ª–µ–º–µ–Ω—Ç {aria_describedby} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ',
                    'explanation': '–°—Ç–≤–æ—Ä—ñ—Ç—å –µ–ª–µ–º–µ–Ω—Ç –∑ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–º ID –¥–ª—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É'
                })
        else:
            details.append({
                'feature': 'aria-describedby',
                'status': 'missing',
                'score': 0.0,
                'description': '–í—ñ–¥—Å—É—Ç–Ω—ñ–π –∑–≤\'—è–∑–æ–∫ –∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è–º –ø—Ä–æ –ø–æ–º–∏–ª–∫—É',
                'explanation': '–î–æ–¥–∞–π—Ç–µ aria-describedby="error-id" —Ç–∞ —Å—Ç–≤–æ—Ä—ñ—Ç—å –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π –µ–ª–µ–º–µ–Ω—Ç'
            })
        
        # 4. role="alert" –µ–ª–µ–º–µ–Ω—Ç–∏ - 0.1
        has_alerts = understandability_metrics._check_alert_elements_exist(html_content)
        if has_alerts:
            details.append({
                'feature': 'role="alert"',
                'status': 'success',
                'score': 0.1,
                'description': '–ù–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ —î –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ role="alert"',
                'explanation': '–°–∫—Ä—ñ–Ω-—Ä—ñ–¥–µ—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–≥–æ–ª–æ—Å—è—Ç—å –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏'
            })
        else:
            details.append({
                'feature': 'role="alert"',
                'status': 'missing',
                'score': 0.0,
                'description': '–í—ñ–¥—Å—É—Ç–Ω—ñ alert –µ–ª–µ–º–µ–Ω—Ç–∏ –Ω–∞ —Å—Ç–æ—Ä—ñ–Ω—Ü—ñ',
                'explanation': '–î–æ–¥–∞–π—Ç–µ role="alert" –¥–æ –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è–º–∏ –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏'
            })
        
        return details
    
    def _analyze_phase2_details(self, field, html_content: str, understandability_metrics) -> List[Dict[str, Any]]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –§–∞–∑–∏ 2 –¥–ª—è UI"""
        
        details = []
        error_messages = understandability_metrics._find_error_messages_for_field(field, html_content)
        
        if not error_messages:
            details.append({
                'feature': '–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏',
                'status': 'missing',
                'score': 0.0,
                'description': '–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ',
                'explanation': '–°—Ç–≤–æ—Ä—ñ—Ç—å –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è–º–∏ —Ç–∞ –∑–≤\'—è–∂—ñ—Ç—å —á–µ—Ä–µ–∑ aria-describedby'
            })
            return details
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∫–æ–∂–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
        total_quality = 0.0
        for i, message in enumerate(error_messages, 1):
            message_quality = understandability_metrics._assess_error_message_quality(message)
            total_quality += message_quality
            
            # –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —è–∫–æ—Å—Ç—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
            quality_details = self._analyze_message_quality(message)
            
            status = 'success' if message_quality >= 0.7 else 'warning' if message_quality >= 0.4 else 'error'
            
            details.append({
                'feature': f'–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è {i}',
                'status': status,
                'score': message_quality,
                'description': f'"{message}" (—è–∫—ñ—Å—Ç—å: {message_quality:.2f})',
                'explanation': quality_details,
                'message_text': message
            })
        
        # –ó–∞–≥–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞
        average_quality = total_quality / len(error_messages)
        phase2_score = average_quality * 0.3
        
        details.insert(0, {
            'feature': '–ó–∞–≥–∞–ª—å–Ω–∞ —è–∫—ñ—Å—Ç—å –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å',
            'status': 'info',
            'score': phase2_score,
            'description': f'–°–µ—Ä–µ–¥–Ω—è —è–∫—ñ—Å—Ç—å: {average_quality:.2f}, —Ñ—ñ–Ω–∞–ª—å–Ω–∏–π —Å–∫–æ—Ä: {phase2_score:.3f}',
            'explanation': f'–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ {len(error_messages)} –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∏–π —Å–∫–æ—Ä —Ñ–∞–∑–∏: 0.3'
        })
        
        return details
    
    def _analyze_phase3_details(self, field, html_content: str, understandability_metrics) -> List[Dict[str, Any]]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –§–∞–∑–∏ 3 –¥–ª—è UI"""
        
        details = []
        
        # 1. Live regions - 0.15
        has_live_regions = understandability_metrics._check_live_regions_exist(html_content)
        if has_live_regions:
            details.append({
                'feature': 'Live regions',
                'status': 'success',
                'score': 0.15,
                'description': '–ó–Ω–∞–π–¥–µ–Ω–æ aria-live –∞–±–æ role="status" –µ–ª–µ–º–µ–Ω—Ç–∏',
                'explanation': '–°–∫—Ä—ñ–Ω-—Ä—ñ–¥–µ—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –æ–≥–æ–ª–æ—Å—è—Ç—å –¥–∏–Ω–∞–º—ñ—á–Ω—ñ –∑–º—ñ–Ω–∏'
            })
        else:
            details.append({
                'feature': 'Live regions',
                'status': 'missing',
                'score': 0.0,
                'description': '–í—ñ–¥—Å—É—Ç–Ω—ñ live regions',
                'explanation': '–î–æ–¥–∞–π—Ç–µ aria-live="polite" –∞–±–æ role="status" –¥–ª—è –¥–∏–Ω–∞–º—ñ—á–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å'
            })
        
        # 2. JavaScript –≤–∞–ª—ñ–¥–∞—Ü—ñ—è - 0.15
        has_js_validation = understandability_metrics._detect_javascript_validation(field, html_content)
        if has_js_validation:
            details.append({
                'feature': 'JavaScript –≤–∞–ª—ñ–¥–∞—Ü—ñ—è',
                'status': 'success',
                'score': 0.15,
                'description': '–í–∏—è–≤–ª–µ–Ω–æ JavaScript –∫–æ–¥ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó',
                'explanation': '–Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –ø–æ–∫—Ä–∞—â—É—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—Ü—å–∫–∏–π –¥–æ—Å–≤—ñ–¥'
            })
        else:
            details.append({
                'feature': 'JavaScript –≤–∞–ª—ñ–¥–∞—Ü—ñ—è',
                'status': 'missing',
                'score': 0.0,
                'description': 'JavaScript –≤–∞–ª—ñ–¥–∞—Ü—ñ—è –Ω–µ –≤–∏—è–≤–ª–µ–Ω–∞',
                'explanation': '–î–æ–¥–∞–π—Ç–µ —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É –≤–∞–ª—ñ–¥–∞—Ü—ñ—é –¥–ª—è –º–∏—Ç—Ç—î–≤–æ–≥–æ –∑–≤–æ—Ä–æ—Ç–Ω–æ–≥–æ –∑–≤\'—è–∑–∫—É'
            })
        
        return details
    
    def _analyze_message_quality(self, message_text: str) -> str:
        """–ê–Ω–∞–ª—ñ–∑ —è–∫–æ—Å—Ç—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É"""
        
        issues = []
        strengths = []
        
        # –î–æ–≤–∂–∏–Ω–∞
        length = len(message_text)
        if 10 <= length <= 100:
            strengths.append("–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞")
        elif 5 <= length <= 150:
            strengths.append("–ø—Ä–∏–π–Ω—è—Ç–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞")
        else:
            if length < 5:
                issues.append("–∑–∞–Ω–∞–¥—Ç–æ –∫–æ—Ä–æ—Ç–∫–µ")
            else:
                issues.append("–∑–∞–Ω–∞–¥—Ç–æ –¥–æ–≤–≥–µ")
        
        # –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ñ—Å—Ç—å
        constructive_words = ['–≤–≤–µ–¥—ñ—Ç—å', '–≤–∏–±–µ—Ä—ñ—Ç—å', '–ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ', '–º–∞—î –º—ñ—Å—Ç–∏—Ç–∏', '—Ñ–æ—Ä–º–∞—Ç', 'please', 'enter', 'select', 'check']
        if any(word in message_text.lower() for word in constructive_words):
            strengths.append("–∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ñ –ø–æ—Ä–∞–¥–∏")
        else:
            issues.append("–Ω–µ–º–∞—î –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–∏—Ö –ø–æ—Ä–∞–¥")
        
        # –°–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ—Å—Ç—å
        specific_words = ['email', '–ø–∞—Ä–æ–ª—å', '—Ç–µ–ª–µ—Ñ–æ–Ω', '–¥–∞—Ç–∞', '—Å–∏–º–≤–æ–ª—ñ–≤', '—Ü–∏—Ñ—Ä', 'password', 'phone', 'date']
        if any(word in message_text.lower() for word in specific_words):
            strengths.append("—Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è")
        else:
            issues.append("–∑–∞–≥–∞–ª—å–Ω–µ —Ñ–æ—Ä–º—É–ª—é–≤–∞–Ω–Ω—è")
        
        result_parts = []
        if strengths:
            result_parts.append("‚úÖ " + ", ".join(strengths))
        if issues:
            result_parts.append("‚ùå " + ", ".join(issues))
        
        return "; ".join(result_parts) if result_parts else "–ë–∞–∑–æ–≤–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è"
    
    def _get_phase1_explanation(self) -> str:
        """–ü–æ—è—Å–Ω–µ–Ω–Ω—è –§–∞–∑–∏ 1"""
        return ("–ë–∞–∑–æ–≤—ñ –∞—Ç—Ä–∏–±—É—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ, —è–∫—ñ –∑–∞–±–µ–∑–ø–µ—á—É—é—Ç—å –º—ñ–Ω—ñ–º–∞–ª—å–Ω—É –ø—ñ–¥—Ç—Ä–∏–º–∫—É –ø–æ–º–∏–ª–æ–∫. "
                "–í–∫–ª—é—á–∞—î HTML5 –≤–∞–ª—ñ–¥–∞—Ü—ñ—é, ARIA –∞—Ç—Ä–∏–±—É—Ç–∏ –¥–ª—è —Å–∫—Ä—ñ–Ω-—Ä—ñ–¥–µ—Ä—ñ–≤ —Ç–∞ –µ–ª–µ–º–µ–Ω—Ç–∏ –¥–ª—è –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å.")
    
    def _get_phase2_explanation(self) -> str:
        """–ü–æ—è—Å–Ω–µ–Ω–Ω—è –§–∞–∑–∏ 2"""
        return ("–Ø–∫—ñ—Å–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏, —è–∫—ñ –¥–æ–ø–æ–º–∞–≥–∞—é—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞–º –∑—Ä–æ–∑—É–º—ñ—Ç–∏ —Ç–∞ –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ –ø—Ä–æ–±–ª–µ–º–∏. "
                "–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –º–∞—é—Ç—å –±—É—Ç–∏ –∑—Ä–æ–∑—É–º—ñ–ª–∏–º–∏, –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–∏–º–∏ —Ç–∞ —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω–∏–º–∏.")
    
    def _get_phase3_explanation(self) -> str:
        """–ü–æ—è—Å–Ω–µ–Ω–Ω—è –§–∞–∑–∏ 3"""
        return ("–î–∏–Ω–∞–º—ñ—á–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è —Ç–∞ —ñ–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π –∑–≤–æ—Ä–æ—Ç–Ω–∏–π –∑–≤'—è–∑–æ–∫. "
                "–í–∫–ª—é—á–∞—î live regions –¥–ª—è —Å–∫—Ä—ñ–Ω-—Ä—ñ–¥–µ—Ä—ñ–≤ —Ç–∞ JavaScript –¥–ª—è –º–∏—Ç—Ç—î–≤–æ—ó –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó.")
    
    def _summarize_form_features(self, field_details: List[Dict[str, Any]]) -> str:
        """–°—Ç–≤–æ—Ä—é—î –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å —Ñ—É–Ω–∫—Ü—ñ–π –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –ø–æ–º–∏–ª–æ–∫ —Ñ–æ—Ä–º–∏"""
        
        if not field_details:
            return "–ù–µ–º–∞—î –ø–æ–ª—ñ–≤ –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó"
        
        features = []
        
        # –ü—ñ–¥—Ä–∞—Ö—É–Ω–æ–∫ —Ñ—É–Ω–∫—Ü—ñ–π –ø–æ —Ñ–∞–∑–∞—Ö
        phase1_features = 0
        phase2_features = 0
        phase3_features = 0
        
        for field in field_details:
            if field.get('phase1_score', 0) > 0:
                phase1_features += 1
            if field.get('phase2_score', 0) > 0:
                phase2_features += 1
            if field.get('phase3_score', 0) > 0:
                phase3_features += 1
        
        total_fields = len(field_details)
        
        if phase1_features > 0:
            features.append(f"–ë–∞–∑–æ–≤–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞: {phase1_features}/{total_fields} –ø–æ–ª—ñ–≤")
        if phase2_features > 0:
            features.append(f"–Ø–∫—ñ—Å–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è: {phase2_features}/{total_fields} –ø–æ–ª—ñ–≤")
        if phase3_features > 0:
            features.append(f"–î–∏–Ω–∞–º—ñ—á–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è: {phase3_features}/{total_fields} –ø–æ–ª—ñ–≤")
        
        if not features:
            features.append("–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ –ø–æ–º–∏–ª–æ–∫")
        
        return '; '.join(features)
    
    def _identify_form_issues(self, field_details: List[Dict[str, Any]], form_quality: float) -> List[str]:
        """–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫—É—î –ø—Ä–æ–±–ª–µ–º–∏ –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –ø–æ–º–∏–ª–æ–∫ —Ñ–æ—Ä–º–∏"""
        
        issues = []
        
        if not field_details:
            issues.append("–ù–µ–º–∞—î –ø–æ–ª—ñ–≤ —â–æ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó")
            return issues
        
        # –ê–Ω–∞–ª—ñ–∑ –ø–æ —Ñ–∞–∑–∞—Ö
        phase1_count = sum(1 for field in field_details if field.get('phase1_score', 0) > 0)
        phase2_count = sum(1 for field in field_details if field.get('phase2_score', 0) > 0)
        phase3_count = sum(1 for field in field_details if field.get('phase3_score', 0) > 0)
        
        total_fields = len(field_details)
        
        if phase1_count == 0:
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—è –±–∞–∑–æ–≤–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ –ø–æ–º–∏–ª–æ–∫ (aria-invalid, –≤–∞–ª—ñ–¥–∞—Ü—ñ—è)")
        elif phase1_count < total_fields:
            issues.append(f"–ù–µ–ø–æ–≤–Ω–∞ –±–∞–∑–æ–≤–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ ({phase1_count}/{total_fields} –ø–æ–ª—ñ–≤)")
        
        if phase2_count == 0:
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—ñ —è–∫—ñ—Å–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏")
        elif phase2_count < total_fields / 2:
            issues.append(f"–ú–∞–ª–æ —è–∫—ñ—Å–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å ({phase2_count}/{total_fields} –ø–æ–ª—ñ–≤)")
        
        if phase3_count == 0:
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—è –¥–∏–Ω–∞–º—ñ—á–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è")
        
        if form_quality < 0.3:
            issues.append(f"–î—É–∂–µ –Ω–∏–∑—å–∫–∞ —è–∫—ñ—Å—Ç—å –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –ø–æ–º–∏–ª–æ–∫ ({form_quality:.2f})")
        elif form_quality < 0.5:
            issues.append(f"–ù–∏–∑—å–∫–∞ —è–∫—ñ—Å—Ç—å –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –ø–æ–º–∏–ª–æ–∫ ({form_quality:.2f})")
        
        return issues
    
    def _summarize_dynamic_features(self, dynamic_test_result: Dict[str, Any]) -> str:
        """–°—Ç–≤–æ—Ä—é—î –æ–ø–∏—Å —Ñ—É–Ω–∫—Ü—ñ–π –¥–∏–Ω–∞–º—ñ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è"""
        
        if not dynamic_test_result or 'error' in dynamic_test_result:
            return "–î–∏–Ω–∞–º—ñ—á–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–µ –≤–¥–∞–ª–æ—Å—è"
        
        features = []
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–∏–Ω–∞–º—ñ—á–Ω–æ–≥–æ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        if dynamic_test_result.get('has_error_response'):
            features.append("–†–µ–∞–≥—É—î –Ω–∞ –ø–æ–º–∏–ª–∫–∏")
        
        if dynamic_test_result.get('field_specific_errors'):
            features.append("–ü–æ–ª–µ-—Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è")
        elif dynamic_test_result.get('general_error_message'):
            features.append("–ó–∞–≥–∞–ª—å–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è")
        
        if dynamic_test_result.get('aria_updates'):
            features.append("ARIA –æ–Ω–æ–≤–ª–µ–Ω–Ω—è")
        
        if dynamic_test_result.get('focus_management'):
            features.append("–£–ø—Ä–∞–≤–ª—ñ–Ω–Ω—è —Ñ–æ–∫—É—Å–æ–º")
        
        error_count = len(dynamic_test_result.get('error_messages', []))
        if error_count > 0:
            features.append(f"{error_count} –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å")
        
        return "; ".join(features) if features else "–ë–∞–∑–æ–≤–∞ –¥–∏–Ω–∞–º—ñ—á–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞"
    
    def _summarize_hybrid_form_features(self, field_details: List[Dict[str, Any]], dynamic_test_result: Dict[str, Any]) -> str:
        """–°—Ç–≤–æ—Ä—é—î –∫–æ—Ä–æ—Ç–∫–∏–π –æ–ø–∏—Å —Ñ—É–Ω–∫—Ü—ñ–π –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –ø–æ–º–∏–ª–æ–∫ —Ñ–æ—Ä–º–∏ (–≥—ñ–±—Ä–∏–¥–Ω–∏–π)"""
        
        if not field_details:
            return "–ù–µ–º–∞—î –ø–æ–ª—ñ–≤ –¥–ª—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó"
        
        # –°—Ç–∞—Ç–∏—á–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
        static_features = []
        phase1_features = sum(1 for field in field_details if field.get('phase1_score', 0) > 0)
        phase2_features = sum(1 for field in field_details if field.get('phase2_score', 0) > 0)
        phase3_features = sum(1 for field in field_details if field.get('phase3_score', 0) > 0)
        
        total_fields = len(field_details)
        
        if phase1_features > 0:
            static_features.append(f"–ë–∞–∑–æ–≤–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞: {phase1_features}/{total_fields}")
        if phase2_features > 0:
            static_features.append(f"–Ø–∫—ñ—Å–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è: {phase2_features}/{total_fields}")
        if phase3_features > 0:
            static_features.append(f"–°—Ç–∞—Ç–∏—á–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è: {phase3_features}/{total_fields}")
        
        # –î–∏–Ω–∞–º—ñ—á–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
        dynamic_features = []
        if dynamic_test_result and 'error' not in dynamic_test_result:
            if dynamic_test_result.get('has_error_response'):
                dynamic_features.append("–î–∏–Ω–∞–º—ñ—á–Ω–∏–π –≤—ñ–¥–≥—É–∫")
            if dynamic_test_result.get('field_specific_errors'):
                dynamic_features.append("–õ–æ–∫–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –ø–æ–º–∏–ª–∫–∏")
            if dynamic_test_result.get('aria_updates'):
                dynamic_features.append("ARIA –æ–Ω–æ–≤–ª–µ–Ω–Ω—è")
        
        # –ö–æ–º–±—ñ–Ω—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        all_features = []
        if static_features:
            all_features.append("–°—Ç–∞—Ç–∏—á–Ω–æ: " + "; ".join(static_features))
        if dynamic_features:
            all_features.append("–î–∏–Ω–∞–º—ñ—á–Ω–æ: " + "; ".join(dynamic_features))
        
        if not all_features:
            all_features.append("–ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ –ø–æ–º–∏–ª–æ–∫")
        
        return " | ".join(all_features)
    
    def _identify_hybrid_form_issues(self, field_details: List[Dict[str, Any]], combined_quality: float, dynamic_test_result: Dict[str, Any]) -> List[str]:
        """–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫—É—î –ø—Ä–æ–±–ª–µ–º–∏ –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –ø–æ–º–∏–ª–æ–∫ —Ñ–æ—Ä–º–∏ (–≥—ñ–±—Ä–∏–¥–Ω–∏–π –∞–Ω–∞–ª—ñ–∑)"""
        
        issues = []
        
        if not field_details:
            issues.append("–ù–µ–º–∞—î –ø–æ–ª—ñ–≤ —â–æ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó")
            return issues
        
        # –°—Ç–∞—Ç–∏—á–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏
        phase1_count = sum(1 for field in field_details if field.get('phase1_score', 0) > 0)
        phase2_count = sum(1 for field in field_details if field.get('phase2_score', 0) > 0)
        total_fields = len(field_details)
        
        if phase1_count == 0:
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—è –±–∞–∑–æ–≤–∞ —Å—Ç–∞—Ç–∏—á–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞")
        elif phase1_count < total_fields:
            issues.append(f"–ù–µ–ø–æ–≤–Ω–∞ —Å—Ç–∞—Ç–∏—á–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ ({phase1_count}/{total_fields})")
        
        if phase2_count == 0:
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—ñ —Å—Ç–∞—Ç–∏—á–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è")
        
        # –î–∏–Ω–∞–º—ñ—á–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏
        if dynamic_test_result:
            if 'error' in dynamic_test_result:
                issues.append(f"–î–∏–Ω–∞–º—ñ—á–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–µ –≤–¥–∞–ª–æ—Å—è: {dynamic_test_result['error']}")
            else:
                if not dynamic_test_result.get('has_error_response'):
                    issues.append("–§–æ—Ä–º–∞ –Ω–µ —Ä–µ–∞–≥—É—î –Ω–∞ –Ω–µ–≤–∞–ª—ñ–¥–Ω—ñ –¥–∞–Ω—ñ")
                
                if not dynamic_test_result.get('field_specific_errors') and not dynamic_test_result.get('general_error_message'):
                    issues.append("–í—ñ–¥—Å—É—Ç–Ω—ñ –¥–∏–Ω–∞–º—ñ—á–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏")
                
                if not dynamic_test_result.get('aria_updates'):
                    issues.append("ARIA –∞—Ç—Ä–∏–±—É—Ç–∏ –Ω–µ –æ–Ω–æ–≤–ª—é—é—Ç—å—Å—è")
        else:
            issues.append("–î–∏–Ω–∞–º—ñ—á–Ω–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –Ω–µ –≤–∏–∫–æ–Ω—É–≤–∞–ª–æ—Å—è")
        
        # –ó–∞–≥–∞–ª—å–Ω–∞ —è–∫—ñ—Å—Ç—å
        if combined_quality < 0.3:
            issues.append(f"–î—É–∂–µ –Ω–∏–∑—å–∫–∞ –∑–∞–≥–∞–ª—å–Ω–∞ —è–∫—ñ—Å—Ç—å ({combined_quality:.2f})")
        elif combined_quality < 0.5:
            issues.append(f"–ù–∏–∑—å–∫–∞ –∑–∞–≥–∞–ª—å–Ω–∞ —è–∫—ñ—Å—Ç—å ({combined_quality:.2f})")
        
        return issues
    
    def _identify_error_support_issues(self, form, html_content: str) -> list:
        """–Ü–¥–µ–Ω—Ç–∏—Ñ—ñ–∫—É—î –ø—Ä–æ–±–ª–µ–º–∏ –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –ø–æ–º–∏–ª–æ–∫"""
        
        issues = []
        
        fields = form.find_all(['input', 'textarea', 'select'])
        validatable_fields = []
        
        from accessibility_evaluator.core.metrics.understandability import UnderstandabilityMetrics
        metrics = UnderstandabilityMetrics()
        
        for field in fields:
            if metrics._field_needs_validation(field):
                validatable_fields.append(field)
        
        if not validatable_fields:
            issues.append("–ù–µ–º–∞—î –ø–æ–ª—ñ–≤ —â–æ –ø–æ—Ç—Ä–µ–±—É—é—Ç—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó")
            return issues
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–∞–≥–∞–ª—å–Ω–∏—Ö –ø—Ä–æ–±–ª–µ–º
        has_validation = any(field.get('required') or field.get('pattern') for field in validatable_fields)
        if not has_validation:
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—è –±–∞–∑–æ–≤–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è (required/pattern)")
        
        has_aria_invalid = any(field.get('aria-invalid') for field in validatable_fields)
        if not has_aria_invalid:
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—ñ aria-invalid –∞—Ç—Ä–∏–±—É—Ç–∏")
        
        has_error_messages = any(field.get('aria-describedby') for field in validatable_fields)
        if not has_error_messages:
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—ñ –∑–≤'—è–∑–∫–∏ –∑ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è–º–∏ –ø—Ä–æ –ø–æ–º–∏–ª–∫–∏ (aria-describedby)")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ live regions
        if not metrics._check_live_regions_exist(html_content):
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—ñ live regions –¥–ª—è –¥–∏–Ω–∞–º—ñ—á–Ω–∏—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å")
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ alert –µ–ª–µ–º–µ–Ω—Ç—ñ–≤
        if not metrics._check_alert_elements_exist(html_content):
            issues.append("–í—ñ–¥—Å—É—Ç–Ω—ñ role='alert' –µ–ª–µ–º–µ–Ω—Ç–∏")
        
        return issues
    
    def _analyze_localization_details(self, page_data: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó"""
        
        html_content = page_data.get('html_content', '')
        url = page_data.get('url', '')
        
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ñ—Å–Ω—É—é—á–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –º–æ–≤
        from accessibility_evaluator.core.metrics.localization import LocalizationMetrics
        localization_metrics = LocalizationMetrics()
        
        detected_languages_set = localization_metrics._detect_available_languages(html_content, url)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –≤ –¥–µ—Ç–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é
        language_names = {
            'uk': '–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞',
            'en': '–ê–Ω–≥–ª—ñ–π—Å—å–∫–∞', 
            'de': '–ù—ñ–º–µ—Ü—å–∫–∞',
            'fr': '–§—Ä–∞–Ω—Ü—É–∑—å–∫–∞',
            'ru': '–†–æ—Å—ñ–π—Å—å–∫–∞',
            'pl': '–ü–æ–ª—å—Å—å–∫–∞'
        }
        
        detected_languages = []
        for lang_code in detected_languages_set:
            lang_name = language_names.get(lang_code, f'–ú–æ–≤–∞ ({lang_code})')
            weight = localization_metrics.weights.get(lang_code, 0.01)
            detected_languages.append({
                'code': lang_code,
                'name': lang_name,
                'weight': weight
            })
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ –≤–∞–∂–ª–∏–≤—ñ –º–æ–≤–∏
        important_languages = ['uk', 'en']
        missing_languages = []
        for lang_code in important_languages:
            if lang_code not in detected_languages_set:
                lang_name = language_names.get(lang_code, f'–ú–æ–≤–∞ ({lang_code})')
                weight = localization_metrics.weights.get(lang_code, 0.01)
                missing_languages.append({
                    'code': lang_code,
                    'name': lang_name,
                    'weight': weight
                })
        
        # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ —Å–∫–æ—Ä—É
        total_score = 0
        for lang in detected_languages:
            total_score += lang['weight']
        
        score_explanation = f"–°–∫–æ—Ä: {total_score:.3f} (–≤–∏—è–≤–ª–µ–Ω–æ {len(detected_languages)} –º–æ–≤)"
        
        return {
            'detected_languages': detected_languages,
            'missing_languages': missing_languages,
            'score_explanation': score_explanation
        }
    
    def _get_axe_rule_results(self, axe_results: Dict[str, Any], result_type: str, rule_id: str) -> Dict[str, Any]:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–∞–≤–∏–ª–∞ axe-core"""
        
        results = axe_results.get(result_type, [])
        for result in results:
            if result.get('id') == rule_id:
                return result
        return {}