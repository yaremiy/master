"""
–ú–µ—Ç—Ä–∏–∫–∏ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ—Å—Ç—ñ (UAC-1.1-G)
"""

from bs4 import BeautifulSoup
from typing import Dict, Any, List
import re


class PerceptibilityMetrics:
    """–ö–ª–∞—Å –¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –º–µ—Ç—Ä–∏–∫ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ—Å—Ç—ñ"""
    
    async def calculate_metrics(self, page_data: Dict[str, Any]) -> Dict[str, float]:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –≤—Å—ñ—Ö –º–µ—Ç—Ä–∏–∫ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        
        Args:
            page_data: –î–∞–Ω—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏ –≤—ñ–¥ WebScraper
            
        Returns:
            –°–ª–æ–≤–Ω–∏–∫ –∑ –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø–µ—Ä—Ü–µ–ø—Ç–∏–≤–Ω–æ—Å—Ç—ñ
        """
        
        return {
            'alt_text': self.calculate_alt_text_metric(page_data),
            'contrast': await self.calculate_contrast_metric(page_data),
            'media_accessibility': self.calculate_media_accessibility_metric(page_data)
        }
    
    def calculate_alt_text_metric(self, page_data: Dict[str, Any]) -> float:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–µ—Ç—Ä–∏–∫–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É (UAC-1.1.1-G) –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º axe-core
        
        –§–æ—Ä–º—É–ª–∞: X = A / B
        A = –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º alt —Ç–µ–∫—Å—Ç–æ–º (–∑ axe-core passes)
        B = –∑–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å (passes + violations)
        """
        
        axe_results = page_data.get('axe_results', {})
        
        print(f"\nüîç === –î–ï–¢–ê–õ–¨–ù–ò–ô –ê–ù–ê–õ–Ü–ó ALT-TEXT –ú–ï–¢–†–ò–ö–ò ===")
        
        # –ó–≥—ñ–¥–Ω–æ –∑ axe-core –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—î—é, –æ—Å–Ω–æ–≤–Ω—ñ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –∑–æ–±—Ä–∞–∂–µ–Ω—å:
        alt_related_rules = ['image-alt', 'input-image-alt', 'area-alt']
        
        total_images = 0
        correct_images = 0
        
        print(f"üìã –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø—Ä–∞–≤–∏–ª–∞: {alt_related_rules}")
        
        for rule_id in alt_related_rules:
            print(f"\nüîç –ü—Ä–∞–≤–∏–ª–æ: {rule_id}")
            
            # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (passes)
            passes = self._get_axe_rule_results(axe_results, 'passes', rule_id)
            if passes:
                passes_count = len(passes.get('nodes', []))
                correct_images += passes_count
                total_images += passes_count
                print(f"   ‚úÖ Passes: {passes_count} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –¥–µ—Ç–∞–ª—ñ –ø–µ—Ä—à–∏—Ö –∫—ñ–ª—å–∫–æ—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤
                nodes = passes.get('nodes', [])[:3]  # –ü–µ—Ä—à—ñ 3 –µ–ª–µ–º–µ–Ω—Ç–∏
                for i, node in enumerate(nodes):
                    target = node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])
                    html = node.get('html', '–Ω–µ–º–∞—î HTML')[:100] + '...' if len(node.get('html', '')) > 100 else node.get('html', '–Ω–µ–º–∞—î HTML')
                    print(f"     {i+1}. Target: {target}")
                    print(f"        HTML: {html}")
            else:
                print(f"   ‚úÖ Passes: 0 –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
            
            # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ –ø—Ä–æ–±–ª–µ–º–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è (violations)
            violations = self._get_axe_rule_results(axe_results, 'violations', rule_id)
            if violations:
                violations_count = len(violations.get('nodes', []))
                total_images += violations_count
                print(f"   ‚ùå Violations: {violations_count} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
                print(f"   üìù –û–ø–∏—Å –ø—Ä–æ–±–ª–µ–º–∏: {violations.get('description', '–Ω–µ–º–∞—î –æ–ø–∏—Å—É')}")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –¥–µ—Ç–∞–ª—ñ –ø–µ—Ä—à–∏—Ö –∫—ñ–ª—å–∫–æ—Ö –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤
                nodes = violations.get('nodes', [])[:3]  # –ü–µ—Ä—à—ñ 3 –µ–ª–µ–º–µ–Ω—Ç–∏
                for i, node in enumerate(nodes):
                    target = node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])
                    html = node.get('html', '–Ω–µ–º–∞—î HTML')[:100] + '...' if len(node.get('html', '')) > 100 else node.get('html', '–Ω–µ–º–∞—î HTML')
                    failure_summary = node.get('failureSummary', '–Ω–µ–º–∞—î –æ–ø–∏—Å—É –ø–æ–º–∏–ª–∫–∏')
                    print(f"     {i+1}. Target: {target}")
                    print(f"        HTML: {html}")
                    print(f"        –ü—Ä–æ–±–ª–µ–º–∞: {failure_summary}")
                # correct_images –ù–ï –∑–±—ñ–ª—å—à—É—î–º–æ –¥–ª—è violations
            else:
                print(f"   ‚ùå Violations: 0 –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
        
        print(f"\nüìä –ü–Ü–î–°–£–ú–û–ö ALT-TEXT:")
        print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å: {correct_images}")
        print(f"   –ó–∞–≥–∞–ª—å–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å: {total_images}")

        # –Ø–∫—â–æ axe-core –Ω–µ –∑–Ω–∞–π—à–æ–≤ –∑–æ–±—Ä–∞–∂–µ–Ω—å, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback –∞–Ω–∞–ª—ñ–∑ HTML
        if total_images == 0:
            print(f"   ‚ö†Ô∏è axe-core –Ω–µ –∑–Ω–∞–π—à–æ–≤ –∑–æ–±—Ä–∞–∂–µ–Ω—å. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback –∞–Ω–∞–ª—ñ–∑ HTML...")
            return self._fallback_alt_text_analysis(page_data)

        # –§–æ—Ä–º—É–ª–∞: X = A / B
        score = correct_images / total_images
        print(f"   üéØ –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫: {correct_images} / {total_images} = {score:.3f}")
        print(f"=== –ö–Ü–ù–ï–¶–¨ ALT-TEXT –ê–ù–ê–õ–Ü–ó–£ ===\n")

        return score
    
    def _fallback_alt_text_analysis(self, page_data: Dict[str, Any]) -> float:
        """Fallback –∞–Ω–∞–ª—ñ–∑ alt-text –∫–æ–ª–∏ axe-core –Ω–µ –∑–Ω–∞–π—à–æ–≤ –∑–æ–±—Ä–∞–∂–µ–Ω—å"""

        html_content = page_data.get('html_content', '')
        if not html_content:
            print("   ‚ö†Ô∏è HTML –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π - –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ 1.0")
            return 1.0

        soup = BeautifulSoup(html_content, 'html.parser')
        images = soup.find_all('img')

        print(f"\nüîç FALLBACK –ê–ù–ê–õ–Ü–ó:")
        print(f"   –ó–Ω–∞–π–¥–µ–Ω–æ <img> —Ç–µ–≥—ñ–≤ —É HTML: {len(images)}")

        if len(images) == 0:
            print(f"   ‚úÖ –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤—ñ–¥—Å—É—Ç–Ω—ñ –≤ HTML - –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ 1.0")
            return 1.0

        correct_images = 0
        for img in images:
            alt = img.get('alt')
            # –ü—Ä–∞–≤–∏–ª—å–Ω–∏–º –≤–≤–∞–∂–∞—î—Ç—å—Å—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑:
            # 1. –ù–µ–ø–æ—Ä–æ–∂–Ω—ñ–º alt (–Ω–µ –¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω–µ)
            # 2. alt="" (–¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è)
            # –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–º –≤–≤–∞–∂–∞—î—Ç—å—Å—è –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å alt –≤–∑–∞–≥–∞–ª—ñ
            if alt is not None:
                correct_images += 1

        score = correct_images / len(images)
        print(f"   –ó–æ–±—Ä–∞–∂–µ–Ω—å –∑ alt –∞—Ç—Ä–∏–±—É—Ç–æ–º: {correct_images}/{len(images)}")
        print(f"   üéØ Fallback —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫: {correct_images} / {len(images)} = {score:.3f}")
        print(f"=== –ö–Ü–ù–ï–¶–¨ FALLBACK –ê–ù–ê–õ–Ü–ó–£ ===\n")

        return score

    async def _fallback_contrast_analysis(self, page_data: Dict[str, Any]) -> float:
        """Fallback –∞–Ω–∞–ª—ñ–∑ –∫–æ–Ω—Ç—Ä–∞—Å—Ç—É –∫–æ–ª–∏ axe-core –Ω–µ –∑–Ω–∞–π—à–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤"""

        html_content = page_data.get('html_content', '')
        if not html_content:
            print("   ‚ö†Ô∏è HTML –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π - –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ 0.8")
            return 0.8  # –ü—Ä–∏–ø—É—Å–∫–∞—î–º–æ —Å–µ—Ä–µ–¥–Ω—ñ–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç

        soup = BeautifulSoup(html_content, 'html.parser')

        # –®—É–∫–∞—î–º–æ —Ç–µ–∫—Å—Ç–æ–≤—ñ –µ–ª–µ–º–µ–Ω—Ç–∏
        text_selectors = ['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'span', 'div', 'a', 'button', 'label', 'li']
        text_elements = []

        for selector in text_selectors:
            elements = soup.find_all(selector)
            for elem in elements:
                text = elem.get_text(strip=True)
                if text and len(text) > 0:  # –¢—ñ–ª—å–∫–∏ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ —Ç–µ–∫—Å—Ç–æ–º
                    text_elements.append(elem)
                    if len(text_elements) >= 50:  # –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
                        break
            if len(text_elements) >= 50:
                break

        print(f"\nüîç FALLBACK –ê–ù–ê–õ–Ü–ó –ö–û–ù–¢–†–ê–°–¢–£:")
        print(f"   –ó–Ω–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ —É HTML: {len(text_elements)}")

        if len(text_elements) == 0:
            print(f"   ‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –≤—ñ–¥—Å—É—Ç–Ω—ñ –≤ HTML - –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ 1.0")
            return 1.0

        # –û—Å–∫—ñ–ª—å–∫–∏ –º–∏ –Ω–µ –º–æ–∂–µ–º–æ –æ–±—á–∏—Å–ª–∏—Ç–∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç –±–µ–∑ computed styles,
        # –ø—Ä–∏–ø—É—Å–∫–∞—î–º–æ —â–æ 80% –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –º–∞—é—Ç—å –ø—Ä–∏–π–Ω—è—Ç–Ω–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç
        print(f"   ‚ö†Ô∏è –ù–µ –º–æ–∂–µ–º–æ –æ–±—á–∏—Å–ª–∏—Ç–∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç –±–µ–∑ browser context")
        print(f"   üéØ Fallback: –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ 0.8 (–ø—Ä–∏–ø—É—Å–∫–∞—î–º–æ 80% –ø—Ä–∏–π–Ω—è—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç—É)")
        print(f"=== –ö–Ü–ù–ï–¶–¨ FALLBACK –ê–ù–ê–õ–Ü–ó–£ –ö–û–ù–¢–†–ê–°–¢–£ ===\n")

        return 0.8

    def _get_axe_rule_results(self, axe_results: Dict[str, Any], result_type: str, rule_id: str) -> Dict[str, Any]:
        """–û—Ç—Ä–∏–º–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø—Ä–∞–≤–∏–ª–∞ axe-core"""

        results = axe_results.get(result_type, [])
        for result in results:
            if result.get('id') == rule_id:
                return result
        return {}


    async def calculate_contrast_metric(self, page_data: Dict[str, Any]) -> float:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–µ—Ç—Ä–∏–∫–∏ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—ñ —Ç–µ–∫—Å—Ç—É (UAC-1.1.2-G) –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º axe-core
        
        –§–æ—Ä–º—É–ª–∞: X = A / B
        A = –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –∑ –¥–æ—Å—Ç–∞—Ç–Ω—ñ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç–æ–º (–∑ axe-core passes)
        B = –∑–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ (passes + violations)
        """
        
        axe_results = page_data.get('axe_results', {})
        
        print(f"\nüé® === –î–ï–¢–ê–õ–¨–ù–ò–ô –ê–ù–ê–õ–Ü–ó –ö–û–ù–¢–†–ê–°–¢–£ ===")
        
        # –û—Ç—Ä–∏–º—É—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è –ø—Ä–∞–≤–∏–ª –∫–æ–Ω—Ç—Ä–∞—Å—Ç—É
        contrast_rules = ['color-contrast', 'color-contrast-enhanced']
        
        total_elements = 0
        correct_elements = 0
        
        print(f"üìã –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø—Ä–∞–≤–∏–ª–∞: {contrast_rules}")
        
        for rule_id in contrast_rules:
            print(f"\nüîç –ü—Ä–∞–≤–∏–ª–æ: {rule_id}")
            
            # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ –ø—Ä–∞–≤–∏–ª—å–Ω–∏–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç–æ–º (passes)
            passes = self._get_axe_rule_results(axe_results, 'passes', rule_id)
            if passes:
                passes_count = len(passes.get('nodes', []))
                correct_elements += passes_count
                total_elements += passes_count
                print(f"   ‚úÖ Passes: {passes_count} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –¥–µ—Ç–∞–ª—ñ –ø–µ—Ä—à–∏—Ö –∫—ñ–ª—å–∫–æ—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤
                nodes = passes.get('nodes', [])[:2]  # –ü–µ—Ä—à—ñ 2 –µ–ª–µ–º–µ–Ω—Ç–∏
                for i, node in enumerate(nodes):
                    target = node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])
                    html = node.get('html', '–Ω–µ–º–∞—î HTML')[:80] + '...' if len(node.get('html', '')) > 80 else node.get('html', '–Ω–µ–º–∞—î HTML')
                    print(f"     {i+1}. Target: {target}")
                    print(f"        HTML: {html}")
            else:
                print(f"   ‚úÖ Passes: 0 –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
            
            # –ü—ñ–¥—Ä–∞—Ö–æ–≤—É—î–º–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ –ø—Ä–æ–±–ª–µ–º–Ω–∏–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç–æ–º (violations)
            violations = self._get_axe_rule_results(axe_results, 'violations', rule_id)
            if violations:
                violations_count = len(violations.get('nodes', []))
                total_elements += violations_count
                print(f"   ‚ùå Violations: {violations_count} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
                print(f"   üìù –û–ø–∏—Å –ø—Ä–æ–±–ª–µ–º–∏: {violations.get('description', '–Ω–µ–º–∞—î –æ–ø–∏—Å—É')}")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –¥–µ—Ç–∞–ª—ñ –ø–µ—Ä—à–∏—Ö –∫—ñ–ª—å–∫–æ—Ö –ø—Ä–æ–±–ª–µ–º–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤
                nodes = violations.get('nodes', [])[:2]  # –ü–µ—Ä—à—ñ 2 –µ–ª–µ–º–µ–Ω—Ç–∏
                for i, node in enumerate(nodes):
                    target = node.get('target', ['–Ω–µ–≤—ñ–¥–æ–º–æ'])
                    html = node.get('html', '–Ω–µ–º–∞—î HTML')[:80] + '...' if len(node.get('html', '')) > 80 else node.get('html', '–Ω–µ–º–∞—î HTML')
                    failure_summary = node.get('failureSummary', '–Ω–µ–º–∞—î –æ–ø–∏—Å—É –ø–æ–º–∏–ª–∫–∏')
                    print(f"     {i+1}. Target: {target}")
                    print(f"        HTML: {html}")
                    print(f"        –ü—Ä–æ–±–ª–µ–º–∞: {failure_summary}")
                # correct_elements –ù–ï –∑–±—ñ–ª—å—à—É—î–º–æ –¥–ª—è violations
            else:
                print(f"   ‚ùå Violations: 0 –µ–ª–µ–º–µ–Ω—Ç—ñ–≤")
        
        print(f"\nüìä –ü–Ü–î–°–£–ú–û–ö –ö–û–ù–¢–†–ê–°–¢–£:")
        print(f"   –ü—Ä–∞–≤–∏–ª—å–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤: {correct_elements}")
        print(f"   –ó–∞–≥–∞–ª—å–Ω–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤: {total_elements}")

        # –Ø–∫—â–æ axe-core –Ω–µ –∑–Ω–∞–π—à–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback
        if total_elements == 0:
            print(f"   ‚ö†Ô∏è axe-core –Ω–µ –∑–Ω–∞–π—à–æ–≤ —Ç–µ–∫—Å—Ç–æ–≤–∏—Ö –µ–ª–µ–º–µ–Ω—Ç—ñ–≤. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ fallback –∞–Ω–∞–ª—ñ–∑...")
            return await self._fallback_contrast_analysis(page_data)

        score = correct_elements / total_elements
        print(f"   üéØ –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫: {correct_elements} / {total_elements} = {score:.3f}")
        print(f"=== –ö–Ü–ù–ï–¶–¨ –ê–ù–ê–õ–Ü–ó–£ –ö–û–ù–¢–†–ê–°–¢–£ ===\n")

        return score
    
    def calculate_media_accessibility_metric(self, page_data: Dict[str, Any]) -> float:
        """
        –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—ñ –º–µ–¥—ñ–∞ (UAC-1.1.3-G) –≤–∫–ª—é—á–Ω–æ –∑ embedded –≤—ñ–¥–µ–æ
        
        –§–æ—Ä–º—É–ª–∞: X = A / B
        A = –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤—ñ–¥–µ–æ —ñ–∑ —Å—É–±—Ç–∏—Ç—Ä–∞–º–∏ –∞–±–æ –∞—É–¥—ñ–æ–æ–ø–∏—Å–∞–º–∏
        B = –∑–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –≤—ñ–¥–µ–æ (–Ω–∞—Ç–∏–≤–Ω—ñ + embedded)
        """
        
        media_elements = page_data.get('media_elements', [])
        
        # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –≤—ñ–¥–µ–æ: –Ω–∞—Ç–∏–≤–Ω—ñ HTML5 + embedded
        video_elements = [elem for elem in media_elements if elem['type'] in ['video', 'embedded_video']]
        
        print(f"\nüé¨ === –î–ï–¢–ê–õ–¨–ù–ò–ô –ê–ù–ê–õ–Ü–ó –î–û–°–¢–£–ü–ù–û–°–¢–Ü –ú–ï–î–Ü–ê ===")
        print(f"üìã –ó–Ω–∞–π–¥–µ–Ω–æ –≤—ñ–¥–µ–æ –µ–ª–µ–º–µ–Ω—Ç—ñ–≤: {len(video_elements)}")
        
        if not video_elements:
            print("‚ö†Ô∏è –í—ñ–¥–µ–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ - –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ 1.0")
            return 1.0  # –ù–µ–º–∞—î –≤—ñ–¥–µ–æ = –Ω–µ–º–∞—î –ø—Ä–æ–±–ª–µ–º
        
        accessible_videos = 0
        
        for i, video in enumerate(video_elements, 1):
            video_type = video.get('type', 'unknown')
            platform = video.get('platform', 'native')
            src = video.get('src') or ''
            
            print(f"\nüîç –í—ñ–¥–µ–æ {i}: {video_type}")
            print(f"   –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: {platform}")
            print(f"   URL: {src[:80]}..." if src and len(src) > 80 else f"   URL: {src}")
            
            has_accessibility = False
            accessibility_reasons = []
            
            if video_type == 'video':
                # –ù–∞—Ç–∏–≤–Ω–µ HTML5 –≤—ñ–¥–µ–æ
                tracks = video.get('tracks', [])
                print(f"   –¢—Ä–µ–∫–∏: {len(tracks)}")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤
                for track in tracks:
                    track_kind = track.get('kind', '')
                    if track_kind in ['subtitles', 'captions']:
                        has_accessibility = True
                        accessibility_reasons.append(f"–°—É–±—Ç–∏—Ç—Ä–∏ ({track_kind})")
                        break
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∞—É–¥—ñ–æ–æ–ø–∏—Å—ñ–≤
                if not has_accessibility:
                    for track in tracks:
                        if track.get('kind') == 'descriptions':
                            has_accessibility = True
                            accessibility_reasons.append("–ê—É–¥—ñ–æ–æ–ø–∏—Å–∏")
                            break
            
            elif video_type == 'embedded_video':
                # Embedded –≤—ñ–¥–µ–æ (YouTube, Vimeo —Ç–æ—â–æ)
                has_captions = video.get('has_captions', False)
                caption_check_method = video.get('caption_check_method', 'url_params')
                
                if has_captions:
                    has_accessibility = True
                    if caption_check_method == 'youtube_api':
                        accessibility_reasons.append(f"–°—É–±—Ç–∏—Ç—Ä–∏ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω—ñ YouTube API ({platform})")
                    elif caption_check_method == 'enhanced_url_analysis':
                        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —î —è–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤
                        if any(param in src for param in ['cc_load_policy=1', 'captions=1', 'cc_lang_pref=']):
                            accessibility_reasons.append(f"–°—É–±—Ç–∏—Ç—Ä–∏ –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ URL ({platform})")
                        elif any(param in src for param in ['hl=en', 'hl=uk', 'hl=ru', 'hl=de', 'hl=fr']):
                            accessibility_reasons.append(f"–ô–º–æ–≤—ñ—Ä–Ω—ñ –∞–≤—Ç–æ—Å—É–±—Ç–∏—Ç—Ä–∏ –∑–∞ –º–æ–≤–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ ({platform})")
                        else:
                            accessibility_reasons.append(f"–ô–º–æ–≤—ñ—Ä–Ω—ñ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ —Å—É–±—Ç–∏—Ç—Ä–∏ YouTube (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–µ –≤—ñ–¥–µ–æ)")
                    else:
                        accessibility_reasons.append(f"–°—É–±—Ç–∏—Ç—Ä–∏ –≤ URL ({platform})")
            
            if has_accessibility:
                accessible_videos += 1
                print(f"   ‚úÖ –î–æ—Å—Ç—É–ø–Ω–µ: {', '.join(accessibility_reasons)}")
            else:
                print(f"   ‚ùå –ù–µ–¥–æ—Å—Ç—É–ø–Ω–µ: –í—ñ–¥—Å—É—Ç–Ω—ñ —Å—É–±—Ç–∏—Ç—Ä–∏ —Ç–∞ –∞—É–¥—ñ–æ–æ–ø–∏—Å–∏")
        
        score = accessible_videos / len(video_elements)
        
        print(f"\nüìä –ü–Ü–î–°–£–ú–û–ö –î–û–°–¢–£–ü–ù–û–°–¢–Ü –ú–ï–î–Ü–ê:")
        print(f"   –î–æ—Å—Ç—É–ø–Ω–∏—Ö –≤—ñ–¥–µ–æ: {accessible_videos}")
        print(f"   –ó–∞–≥–∞–ª—å–Ω–∏—Ö –≤—ñ–¥–µ–æ: {len(video_elements)}")
        print(f"   üéØ –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫: {accessible_videos} / {len(video_elements)} = {score:.3f}")
        print(f"=== –ö–Ü–ù–ï–¶–¨ –ê–ù–ê–õ–Ü–ó–£ –ú–ï–î–Ü–ê ===\n")
        
        return score